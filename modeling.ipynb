{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Loading-train-data\" data-toc-modified-id=\"Loading-train-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Loading train data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Merging-train-and-test-data\" data-toc-modified-id=\"Merging-train-and-test-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Merging train and test data</a></span></li><li><span><a href=\"#Merging-user-data\" data-toc-modified-id=\"Merging-user-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Merging user data</a></span></li><li><span><a href=\"#Competitions-based-features\" data-toc-modified-id=\"Competitions-based-features-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Competitions based features</a></span></li><li><span><a href=\"#Competitions-data\" data-toc-modified-id=\"Competitions-data-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Competitions data</a></span></li><li><span><a href=\"#Time-based-competitions-features\" data-toc-modified-id=\"Time-based-competitions-features-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Time based competitions features</a></span></li><li><span><a href=\"#Current-active-competitions-feature\" data-toc-modified-id=\"Current-active-competitions-feature-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Current active competitions feature</a></span></li><li><span><a href=\"#User-Interests-Feature\" data-toc-modified-id=\"User-Interests-Feature-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>User Interests Feature</a></span></li><li><span><a href=\"#Submissions-based-features\" data-toc-modified-id=\"Submissions-based-features-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Submissions based features</a></span></li><li><span><a href=\"#Discussion-based-features\" data-toc-modified-id=\"Discussion-based-features-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Discussion based features</a></span></li><li><span><a href=\"#Comments-based-features\" data-toc-modified-id=\"Comments-based-features-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>Comments based features</a></span></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Modeling</a></span></li><li><span><a href=\"#Submission\" data-toc-modified-id=\"Submission-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Submission</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ast\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from catboost import CatBoostClassifier\n",
    "from category_encoders import CountEncoder\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams[\"axes.labelsize\"] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 14\n",
    "plt.rcParams[\"ytick.labelsize\"] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Config:\n",
    "#     LAG = 3\n",
    "#     VER = f'final_sub_v1'\n",
    "#     OUTPUT_DIR = '.'\n",
    "#     DATA_DIR = '.'\n",
    "#     DEBUG = True\n",
    "#     N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL_TEST_RUN = False\n",
    "seed = 0\n",
    "# def seed_everything(seed=0):\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable\n",
    "def target_var(train):\n",
    "    target = []\n",
    "    for _, row in train.iterrows():\n",
    "        if row['CompPart'] == 1:\n",
    "            target.append('CompPart')\n",
    "            continue\n",
    "        elif row['Sub'] == 1 or row['Comment'] == 1 or row['Disc'] == 1:\n",
    "            target.append('Sub')\n",
    "            continue\n",
    "        else:\n",
    "            target.append('NoActivity')\n",
    "        \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259832, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>CompPart</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sub</th>\n",
       "      <th>Disc</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_XI7BAR4Y</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NoActivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_XI7BAR4Y</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NoActivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_XI7BAR4Y</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NoActivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_XI7BAR4Y</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NoActivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_XI7BAR4Y</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NoActivity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       User_ID  month  year  CompPart  Comment  Sub  Disc      Target\n",
       "0  ID_XI7BAR4Y      8     3         0        0    0     0  NoActivity\n",
       "1  ID_XI7BAR4Y      8     2         0        0    0     0  NoActivity\n",
       "2  ID_XI7BAR4Y      9     2         0        0    0     0  NoActivity\n",
       "3  ID_XI7BAR4Y      9     3         0        0    0     0  NoActivity\n",
       "4  ID_XI7BAR4Y     10     3         0        0    0     0  NoActivity"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read train data\n",
    "train = pd.read_csv(\"./Train.csv\", index_col = None)\n",
    "print(train.shape)\n",
    "\n",
    "# Create target column from existing train data\n",
    "train['Target'] = target_var(train)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65223, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_H1ELY25E</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_H1ELY25E</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_H1ELY25E</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_463Q2BCO</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_463Q2BCO</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       User_ID  month  year\n",
       "0  ID_H1ELY25E      1     4\n",
       "1  ID_H1ELY25E      2     4\n",
       "2  ID_H1ELY25E      3     4\n",
       "3  ID_463Q2BCO      1     4\n",
       "4  ID_463Q2BCO      2     4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read test data\n",
    "test = pd.read_csv(\"./Test.csv\", index_col = None)\n",
    "print(test.shape)\n",
    "\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time columns in dataset\n",
    "def define_timestamp(df):\n",
    "    year_month = df['year'].astype(str) + \\\n",
    "        df['month'].apply(lambda x: str(x).zfill(2))\n",
    "    df['year_month'] = year_month.astype(int)\n",
    "    df = df.sort_values(by = 'year_month').reset_index(drop = True)\n",
    "    df['timestamp'] = np.arange(1, len(df) + 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "\n",
    "data = train.append(test, ignore_index=True)\n",
    "timestamp = data[['year', 'month']].drop_duplicates()\n",
    "timestamp = define_timestamp(timestamp)\n",
    "data = data.merge(timestamp, how = 'left')\n",
    "all_timestamps = data[['User_ID', 'timestamp', 'year', 'month']].drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "data = data.sort_values(by='timestamp').reset_index(drop=True)\n",
    "data['Record'] = 1\n",
    "data['Total_Num_User_Months'] = data.groupby('User_ID')['Record'].apply(lambda x: x.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>FeatureX</th>\n",
       "      <th>Country</th>\n",
       "      <th>FeatureY</th>\n",
       "      <th>Points</th>\n",
       "      <th>Zindi_Joining_Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_N5LTBAPU</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_DMRM</td>\n",
       "      <td>1</td>\n",
       "      <td>group 3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_CLSFQB0S</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_Q02</td>\n",
       "      <td>3</td>\n",
       "      <td>group 3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_RE6T58Y4</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_Q02</td>\n",
       "      <td>0</td>\n",
       "      <td>group 3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_XJQQRJV3</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_Z8BI</td>\n",
       "      <td>0</td>\n",
       "      <td>group 3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_1JHU6A8S</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_Q02</td>\n",
       "      <td>3</td>\n",
       "      <td>group 3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       User_ID  FeatureX  Country  FeatureY   Points  Zindi_Joining_Timestamp\n",
       "0  ID_N5LTBAPU         0  ID_DMRM         1  group 3                       13\n",
       "1  ID_CLSFQB0S         0   ID_Q02         3  group 3                        2\n",
       "2  ID_RE6T58Y4         0   ID_Q02         0  group 3                       21\n",
       "3  ID_XJQQRJV3         0  ID_Z8BI         0  group 3                       18\n",
       "4  ID_1JHU6A8S         0   ID_Q02         3  group 3                       19"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(\"./Users.csv\", index_col=None)\n",
    "users.columns = ['User_ID', 'FeatureX', 'Country', 'FeatureY', 'Points', 'year', 'month', 'dayofweek']\n",
    "users = users.merge(timestamp, how='left')\n",
    "users = users.rename(columns={\"timestamp\": \"Zindi_Joining_Timestamp\"})\n",
    "users.drop(['dayofweek', 'year', 'month', 'year_month'], axis=1, inplace=True)\n",
    "users.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(users, how='left')\n",
    "\n",
    "columns = ['FeatureX', 'Country', 'FeatureY', 'Points']\n",
    "data[columns] = data[columns].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competitions based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_data = pd.read_csv(\"./CompetitionPartipation.csv\", index_col=None)\n",
    "competition_data.columns = [\n",
    "    'CompID', 'User_ID', 'PublicRank', 'Successful_Sub_Count',\n",
    "    'year', 'month', 'dayofweek'\n",
    "]\n",
    "    \n",
    "competition_timestamp = competition_data.merge(timestamp, how='left')\n",
    "competition_timestamp = competition_timestamp[[\n",
    "    'User_ID', 'month', 'year', 'timestamp'\n",
    "]].drop_duplicates()\n",
    "competition_timestamp.columns = [\n",
    "    'User_ID', 'month', 'year', 'comp_timestamp'\n",
    "]\n",
    "data = data.merge(competition_timestamp, how='left')\n",
    "\n",
    "data = data.sort_values(by='timestamp').reset_index(drop=True)\n",
    "data['comp_timestamp'] = data.groupby('User_ID')['comp_timestamp'].apply(lambda x: x.ffill().shift())\n",
    "data['Months_Since_Last_Comp'] = data['timestamp'] - data['comp_timestamp']\n",
    "data['Months_Since_Joining_Zindi'] = data['comp_timestamp'] - data['Zindi_Joining_Timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competitions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitions = pd.read_csv(\"./Competitions.csv\", index_col=None, skipinitialspace=True)\n",
    "competitions['CompEndTime Year'] = [\n",
    "    int(val) if val != 'not mapped' else 999 \\\n",
    "    for val in competitions['CompEndTime Year']\n",
    "]\n",
    "competitions['FeatureC'] = competitions['FeatureC'].fillna(-1).astype(np.int8)\n",
    "competitions = competitions.merge(\n",
    "    timestamp,\n",
    "    left_on=['CompStartTime Year', 'CompStartTime Month'],\n",
    "    right_on=['year', 'month'],\n",
    "    how='left')\n",
    "competitions = competitions.rename(columns={\n",
    "    'timestamp': 'comp_start_timestamp',\n",
    "})\n",
    "competitions.drop(['year', 'month', 'year_month'], axis=1, inplace=True)\n",
    "competitions = competitions.merge(\n",
    "    timestamp,\n",
    "    left_on=['CompEndTime Year', 'CompEndTime Month'],\n",
    "    right_on=['year', 'month'],\n",
    "    how='left')\n",
    "competitions = competitions.rename(columns={\n",
    "    'timestamp': 'comp_end_timestamp',\n",
    "})\n",
    "competitions['comp_end_timestamp'] = competitions['comp_end_timestamp'].fillna(99)\n",
    "competitions.drop(['year', 'month', 'year_month'], axis=1, inplace=True)\n",
    "competitions['comp_duration'] = competitions['comp_end_timestamp'] - competitions['comp_start_timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['FeatureA', 'FeatureB', 'FeatureE']:\n",
    "    competitions[column] = competitions[column].map(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = competitions[['CompID']].copy()\n",
    "for column in ['FeatureA', 'FeatureB', 'FeatureC', 'FeatureD', 'FeatureE']:\n",
    "    table = competitions[['CompID', column]].explode(column=[column])\n",
    "    table[column] = table[column].fillna('empty')\n",
    "    table['count'] = 1\n",
    "\n",
    "    table = table.pivot_table(\n",
    "        index='CompID', \n",
    "        columns=column,\n",
    "        values='count',\n",
    "        aggfunc='count'\n",
    "    )\n",
    "    table.columns = [table.columns.name + \"_\" + str(cl) for cl in table.columns]\n",
    "    table = table.reset_index()\n",
    "    features = features.merge(table, how='left')\n",
    "features = features.fillna(0)\n",
    "features = features.merge(competitions[['CompID', 'comp_start_timestamp']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time based competitions features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 555.24it/s]\n"
     ]
    }
   ],
   "source": [
    "timestamp_inds = []\n",
    "competitions_inds = []\n",
    "\n",
    "for t in tqdm(timestamp.timestamp):\n",
    "    current_competition = competitions.CompID[\n",
    "        (t>=competitions.comp_start_timestamp) & (t<=competitions.comp_end_timestamp)\n",
    "    ]\n",
    "    timestamp_inds.extend([t] * len(current_competition))\n",
    "    competitions_inds.extend(current_competition)\n",
    "\n",
    "timestamp_competition = pd.DataFrame({\n",
    "    \"timestamp\": timestamp_inds,\n",
    "    \"CompID\": competitions_inds\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current active competitions feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_competition = competition_data.merge(timestamp, how='left')\n",
    "current_competition = current_competition.rename(columns={\"timestamp\": \"comp_timestamp\"})\n",
    "current_competition = current_competition[\n",
    "    ['User_ID', 'CompID', 'comp_timestamp']\n",
    "].merge(competitions[\n",
    "    ['CompID', 'comp_start_timestamp', 'comp_end_timestamp']\n",
    "], how='left')\n",
    "current_competition = current_competition[current_competition['comp_end_timestamp']!=99].reset_index(drop=True)\n",
    "current_competition = all_timestamps.merge(current_competition, how='left')\n",
    "\n",
    "current_competition['Current_Active_Competitions'] = (\n",
    "    (current_competition['timestamp'] > current_competition['comp_timestamp']) &\n",
    "    (current_competition['timestamp'] <= current_competition['comp_end_timestamp'])\n",
    ").astype(np.int8)\n",
    "\n",
    "current_competition = current_competition.groupby(['User_ID', 'timestamp'])['Current_Active_Competitions'].sum()\n",
    "current_competition = current_competition.reset_index()\n",
    "\n",
    "data = data.merge(current_competition, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Interests Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FeatureA_1', 'FeatureA_2', 'FeatureA_3', 'FeatureA_4', 'FeatureA_5',\n",
      "       'FeatureA_6', 'FeatureA_7', 'FeatureA_8', 'FeatureA_9', 'FeatureA_10',\n",
      "       'FeatureA_empty', 'FeatureB_5', 'FeatureB_6', 'FeatureB_7',\n",
      "       'FeatureB_8', 'FeatureB_9', 'FeatureB_10', 'FeatureB_12', 'FeatureB_14',\n",
      "       'FeatureB_15', 'FeatureB_16', 'FeatureB_empty', 'FeatureC_-1',\n",
      "       'FeatureC_1', 'FeatureC_2', 'FeatureC_3', 'FeatureC_4', 'FeatureC_5',\n",
      "       'FeatureC_6', 'FeatureC_7', 'FeatureC_8', 'FeatureC_9', 'FeatureC_10',\n",
      "       'FeatureC_11', 'FeatureC_12', 'FeatureC_13', 'FeatureC_14',\n",
      "       'FeatureC_15', 'FeatureC_16', 'FeatureC_17', 'FeatureC_18',\n",
      "       'FeatureC_19', 'FeatureC_20', 'FeatureC_21', 'FeatureC_22',\n",
      "       'FeatureC_23', 'FeatureC_24', 'FeatureC_25', 'FeatureC_26',\n",
      "       'FeatureC_27', 'FeatureC_28', 'FeatureC_29', 'FeatureC_30',\n",
      "       'FeatureC_31', 'FeatureC_32', 'FeatureC_33', 'FeatureC_34',\n",
      "       'FeatureC_35', 'FeatureC_36', 'FeatureC_37', 'FeatureD_1', 'FeatureD_2',\n",
      "       'FeatureD_3', 'FeatureE_1', 'FeatureE_2', 'FeatureE_3', 'FeatureE_4',\n",
      "       'FeatureE_5', 'FeatureE_6', 'FeatureE_7', 'FeatureE_8', 'FeatureE_9',\n",
      "       'FeatureE_10', 'FeatureE_empty'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [08:51<00:00,  7.18s/it]\n"
     ]
    }
   ],
   "source": [
    "timestamp_competition = timestamp_competition.merge(features, how='left')\n",
    "timestamp_competition.drop(['comp_start_timestamp', 'CompID'], axis=1, inplace=True)\n",
    "timestamp_competition = timestamp_competition.groupby('timestamp').agg(np.sum).reset_index()\n",
    "timestamp_competition = timestamp_competition.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "competition_timestamp = competition_data.merge(timestamp, how='left')\n",
    "usr_features = competition_timestamp[['User_ID', 'CompID', 'timestamp']].merge(features, how='left')\n",
    "usr_features = usr_features.drop(['CompID', 'comp_start_timestamp'], axis=1)\n",
    "usr_features = usr_features.groupby(['User_ID', 'timestamp']).agg(np.sum)#.groupby(level=0).cumsum()\n",
    "usr_features = usr_features.reset_index()\n",
    "usr_features = all_timestamps.merge(usr_features, how='left')\n",
    "columns = usr_features.columns[4:]\n",
    "print(columns)\n",
    "\n",
    "usr_features = usr_features.sort_values(by='timestamp').reset_index(drop=True)\n",
    "for cl in tqdm(columns):\n",
    "    usr_features[cl] = usr_features.groupby('User_ID')[cl].apply(lambda x: x.ffill())\n",
    "\n",
    "usr_features = usr_features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "timestamp_inds = []\n",
    "usr_inds = []\n",
    "user_interests = []\n",
    "\n",
    "for t in timestamp_competition['timestamp']:\n",
    "    if t == 1:\n",
    "        continue\n",
    "    usr_filtered = usr_features[usr_features['timestamp']==t-1]\n",
    "    timestamp_inds.extend([t]*len(usr_filtered))\n",
    "    usr_inds.extend(usr_filtered.pop('User_ID'))\n",
    "    \n",
    "    comp_filtered = timestamp_competition[timestamp_competition['timestamp']==t]\n",
    "    usr_filtered.drop(['timestamp', 'year', 'month'], axis=1, inplace=True)\n",
    "    comp_filtered.drop('timestamp', axis=1, inplace=True)\n",
    "    \n",
    "    interests = np.matmul(usr_filtered.values, comp_filtered.values.T).flatten()\n",
    "#     interests = cosine_similarity(usr_filtered.values, comp_filtered.values).flatten()\n",
    "    user_interests.extend(interests)\n",
    "\n",
    "usr_interest_f = pd.DataFrame({\n",
    "    \"timestamp\": timestamp_inds,\n",
    "    \"User_ID\": usr_inds,\n",
    "    \"user_interests\": user_interests\n",
    "})\n",
    "\n",
    "data = data.merge(usr_interest_f, how='left')\n",
    "data = data.sort_values(by='timestamp').reset_index(drop=True)\n",
    "data['user_interests'] = data.groupby('User_ID')['user_interests'].apply(lambda x: x.ffill())\n",
    "data['user_interests'] = data['user_interests'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = competition_data.groupby(['User_ID', 'year', 'month'])['CompID'].nunique()\n",
    "history = history.reset_index()\n",
    "history.columns = [*history.columns[:-1]] + ['Num_Comp_Prev_Month']\n",
    "\n",
    "data = data.merge(history, how='left')\n",
    "data = data.sort_values(by=['User_ID', 'timestamp']).reset_index(drop=True)\n",
    "data['Num_Comp_Prev_Month'] = data['Num_Comp_Prev_Month'].fillna(0)\n",
    "data['Num_Comp_Per_Month'] = data.groupby('User_ID')['Num_Comp_Prev_Month'].cumsum()\n",
    "data['Num_Comp_Per_Month_trend'] = data['Num_Comp_Per_Month']/data['Total_Num_User_Months']\n",
    "data['Num_Comp_Per_Month_trend'] = data.groupby('User_ID')['Num_Comp_Per_Month_trend'].apply(lambda x: x.shift())\n",
    "data['Num_Comp_Per_Month'] = data['Num_Comp_Per_Month']/(data['timestamp'].max() - data['Zindi_Joining_Timestamp'])\n",
    "data['Num_Comp_Per_Month'] = data.groupby('User_ID')['Num_Comp_Per_Month'].apply(lambda x: x.shift())\n",
    "\n",
    "data['Num_Comp_Prev_Month'] = data.groupby('User_ID')['Num_Comp_Prev_Month'].apply(lambda x: x.shift())\n",
    "data['Num_Comp_Prev_Month_momentum'] = data['Num_Comp_Prev_Month'] - data.groupby('User_ID')['Num_Comp_Prev_Month'].apply(lambda x: x.shift(1))\n",
    "data['Num_Comp_Prev_Month_momentum2'] = data['Num_Comp_Prev_Month'] - data.groupby('User_ID')['Num_Comp_Prev_Month'].apply(lambda x: x.shift(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = competition_data.groupby(['User_ID', 'year', 'month', 'PublicRank'])['CompID'] \\\n",
    "    .nunique().unstack('PublicRank').apply(lambda x: x/x.sum(), axis=1)\n",
    "col_names = [table.columns.name + \"_\" + str(cl) for cl in table.columns]\n",
    "table.columns = col_names\n",
    "table = table.fillna(0)\n",
    "table = table.reset_index()\n",
    "\n",
    "table = all_timestamps.merge(table, how='left')\n",
    "table = table.sort_values(by='timestamp').reset_index(drop=True)\n",
    "for col in col_names:\n",
    "    table[col] = table.groupby('User_ID')[col].apply(lambda x: x.cumsum().ffill().shift())\n",
    "    \n",
    "data = data.merge(table, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = competition_data.groupby(['User_ID', 'year', 'month', 'Successful_Sub_Count'])['CompID'].nunique().unstack('Successful_Sub_Count').apply(lambda x: x/x.sum(), axis=1)\n",
    "col_names = [table.columns.name + \"_\" + str(col) for col in table.columns]\n",
    "table.columns = col_names\n",
    "table = table.fillna(0)\n",
    "table = table.reset_index()\n",
    "\n",
    "table = all_timestamps.merge(table, how='left')\n",
    "table = table.sort_values(by='timestamp').reset_index(drop=True)\n",
    "for col in col_names:\n",
    "    table[col] = table.groupby('User_ID')[col].apply(lambda x: x.cumsum().ffill().shift())\n",
    "    \n",
    "data = data.merge(table, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del competition_data, competition_timestamp, history\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"./Submissions.csv\", index_col=None)\n",
    "submission.columns = ['User_ID', 'FeatureG', 'CompID', 'year', 'month', 'dayofweek']\n",
    "    \n",
    "submission_timestamp = submission.merge(timestamp, how='left')\n",
    "submission_timestamp = submission_timestamp[['User_ID', 'month', 'year', 'timestamp']].drop_duplicates()\n",
    "submission_timestamp.columns = ['User_ID', 'month', 'year', 'sub_timestamp']\n",
    "data = data.merge(submission_timestamp, how='left')\n",
    "\n",
    "data = data.sort_values(by='timestamp').reset_index(drop=True)\n",
    "data['sub_timestamp'] = data.groupby('User_ID')['sub_timestamp'].apply(lambda x: x.ffill().shift())\n",
    "data['Months_Since_Last_Sub'] = data['timestamp'] - data['sub_timestamp']\n",
    "data['Months_Since_Sub_Joining_Zindi'] = data['sub_timestamp'] - data['Zindi_Joining_Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_submission = submission.groupby(['User_ID', 'year', 'month']).agg({'CompID': ['nunique', 'count']})\n",
    "unique_submission.columns = [\"_\".join(col) for col in unique_submission.columns]\n",
    "unique_submission['Sub_Per_Comp'] = unique_submission['CompID_nunique']/unique_submission['CompID_count']\n",
    "unique_submission.drop(['CompID_nunique', 'CompID_count'], axis=1, inplace=True)\n",
    "unique_submission = unique_submission.reset_index()\n",
    "unique_submission.columns = [*unique_submission.columns[:-1]] + ['Num_Sub_Prev_Month']\n",
    "\n",
    "data = data.merge(unique_submission, how='left')\n",
    "data = data.sort_values(by=['User_ID', 'timestamp']).reset_index(drop=True)\n",
    "data['Num_Sub_Prev_Month'] = data['Num_Sub_Prev_Month'].fillna(0)\n",
    "data['Num_Sub_Per_Month'] = data.groupby('User_ID')['Num_Sub_Prev_Month'].cumsum()\n",
    "data['Num_Sub_Per_Month_trend'] = data['Num_Sub_Per_Month']/data['Total_Num_User_Months']\n",
    "data['Num_Sub_Per_Month_trend'] = data.groupby('User_ID')['Num_Sub_Per_Month_trend'].apply(lambda x: x.shift())\n",
    "data['Num_Sub_Per_Month'] = data['Num_Sub_Per_Month']/(data['timestamp'].max() - data['Zindi_Joining_Timestamp'])\n",
    "data['Num_Sub_Per_Month'] = data.groupby('User_ID')['Num_Sub_Per_Month'].apply(lambda x: x.shift())\n",
    "\n",
    "data['Num_Sub_Prev_Month'] = data.groupby('User_ID')['Num_Sub_Prev_Month'].apply(lambda x: x.shift())\n",
    "data['Num_Sub_Prev_Month_momentum'] = data['Num_Sub_Prev_Month'] - data.groupby('User_ID')['Num_Sub_Prev_Month'].apply(lambda x: x.shift(1))\n",
    "data['Num_Sub_Prev_Month_momentum2'] = data['Num_Sub_Prev_Month'] - data.groupby('User_ID')['Num_Sub_Prev_Month'].apply(lambda x: x.shift(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User_ID', 'FeatureG', 'CompID', 'year', 'month', 'dayofweek'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = submission.groupby(['User_ID', 'year', 'month', 'FeatureG'])['CompID'].nunique().unstack('FeatureG')#.apply(lambda x: x/x.sum(), axis=1)\n",
    "col_names = [table.columns.name + \"_\" + str(col) for col in table.columns]\n",
    "table.columns = col_names\n",
    "table = table.fillna(0)\n",
    "table = table.reset_index()\n",
    "\n",
    "all_timestamps = data[['User_ID', 'timestamp', 'year', 'month']].drop_duplicates().reset_index(drop=True)\n",
    "table = all_timestamps.merge(table, how='left')\n",
    "table = table.sort_values(by='timestamp').reset_index(drop=True)\n",
    "for col in col_names:\n",
    "    table[col] = table.groupby('User_ID')[col].apply(lambda x: x.ffill().shift())\n",
    "    \n",
    "data = data.merge(table, how='left')\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del submission, submission_timestamp, unique_submission\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'f'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "discussion = pd.read_csv(\"./Discussions.csv\", index_col=None)\n",
    "discussion.columns = ['FeatureF', 'year', 'month', 'dayofweek', 'DiscID', 'User_ID']\n",
    "    \n",
    "discussion_timestamp = discussion.merge(timestamp, how='left')\n",
    "discussion_timestamp = discussion_timestamp[['User_ID', 'month', 'year', 'timestamp']].drop_duplicates()\n",
    "discussion_timestamp.columns = ['User_ID', 'month', 'year', 'discussion_timestamp']\n",
    "data = data.merge(discussion_timestamp, how='left')\n",
    "\n",
    "data = data.sort_values(by='timestamp').reset_index(drop=True)\n",
    "data['discussion_timestamp'] = data.groupby('User_ID')['discussion_timestamp'].apply(lambda x: x.ffill().shift())\n",
    "data['Months_Since_Last_Dis'] = data['timestamp'] - data['discussion_timestamp']\n",
    "data['Months_Since_Dis_Joining_Zindi'] = data['discussion_timestamp'] - data['Zindi_Joining_Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dish = discussion.groupby(['User_ID', 'year', 'month'])['DiscID'].nunique()\n",
    "dish = dish.reset_index()\n",
    "dish.columns = [*dish.columns[:-1]] + ['Num_Dis_Prev_Month']\n",
    "\n",
    "data = data.merge(dish, how='left')\n",
    "data = data.sort_values(by=['User_ID', 'timestamp']).reset_index(drop=True)\n",
    "data['Num_Dis_Prev_Month'] = data['Num_Dis_Prev_Month'].fillna(0)\n",
    "data['Num_Dis_Per_Month'] = data.groupby('User_ID')['Num_Dis_Prev_Month'].cumsum()\n",
    "data['Num_Dis_Per_Month_trend'] = data['Num_Dis_Per_Month']/data['Total_Num_User_Months']\n",
    "data['Num_Dis_Per_Month_trend'] = data.groupby('User_ID')['Num_Dis_Per_Month_trend'].apply(lambda x: x.shift())\n",
    "data['Num_Dis_Per_Month'] = data['Num_Dis_Per_Month']/(data['timestamp'].max() - data['Zindi_Joining_Timestamp'])\n",
    "data['Num_Dis_Per_Month'] = data.groupby('User_ID')['Num_Dis_Per_Month'].apply(lambda x: x.shift())\n",
    "\n",
    "data['Num_Dis_Prev_Month'] = data.groupby('User_ID')['Num_Dis_Prev_Month'].apply(lambda x: x.shift())\n",
    "data['Num_Dis_Prev_Month_momentum'] = data['Num_Dis_Prev_Month'] - data.groupby('User_ID')['Num_Dis_Prev_Month'].apply(lambda x: x.shift(1))\n",
    "data['Num_Dis_Prev_Month_momentum2'] = data['Num_Dis_Prev_Month'] - data.groupby('User_ID')['Num_Dis_Prev_Month'].apply(lambda x: x.shift(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del discussion, discussion_timestamp, dish\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv(\"./Comments.csv\", index_col=None)\n",
    "comments.columns = ['User_ID', 'year', 'month', 'dayofweek']\n",
    "comments['CommID'] = np.arange(len(comments))\n",
    "    \n",
    "comments_timestamp = comments.merge(timestamp, how='left')\n",
    "comments_timestamp = comments_timestamp[['User_ID', 'month', 'year', 'timestamp']].drop_duplicates()\n",
    "comments_timestamp.columns = ['User_ID', 'month', 'year', 'comment_timestamp']\n",
    "data = data.merge(comments_timestamp, how='left')\n",
    "\n",
    "data = data.sort_values(by='timestamp').reset_index(drop=True)\n",
    "data['comment_timestamp'] = data.groupby('User_ID')['comment_timestamp'].apply(lambda x: x.ffill().shift())\n",
    "data['Months_Since_Last_Comment'] = data['timestamp'] - data['comment_timestamp']\n",
    "data['Months_Since_Comment_Joining_Zindi'] = data['comment_timestamp'] - data['Zindi_Joining_Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_comments = comments.groupby(['User_ID', 'year', 'month'])['CommID'].nunique()\n",
    "unique_comments = unique_comments.reset_index()\n",
    "unique_comments.columns = [*unique_comments.columns[:-1]] + ['Num_Comm_Prev_Month']\n",
    "\n",
    "data = data.merge(unique_comments, how='left')\n",
    "data = data.sort_values(by=['User_ID', 'timestamp']).reset_index(drop=True)\n",
    "data['Num_Comm_Prev_Month'] = data['Num_Comm_Prev_Month'].fillna(0)\n",
    "data['Num_Comm_Per_Month'] = data.groupby('User_ID')['Num_Comm_Prev_Month'].cumsum()\n",
    "data['Num_Comm_Per_Month_trend'] = data['Num_Comm_Per_Month']/data['Total_Num_User_Months']\n",
    "data['Num_Comm_Per_Month_trend'] = data.groupby('User_ID')['Num_Comm_Per_Month_trend'].apply(lambda x: x.shift())\n",
    "data['Num_Comm_Per_Month'] = data['Num_Comm_Per_Month']/(data['timestamp'].max() - data['Zindi_Joining_Timestamp'])\n",
    "data['Num_Comm_Per_Month'] = data.groupby('User_ID')['Num_Comm_Per_Month'].apply(lambda x: x.shift())\n",
    "\n",
    "data['Num_Comm_Prev_Month'] = data.groupby('User_ID')['Num_Comm_Prev_Month'].apply(lambda x: x.shift())\n",
    "data['Num_Comm_Prev_Month_momentum'] = data['Num_Comm_Prev_Month'] - data.groupby('User_ID')['Num_Comm_Prev_Month'].apply(lambda x: x.shift(1))\n",
    "data['Num_Comm_Prev_Month_momentum2'] = data['Num_Comm_Prev_Month'] - data.groupby('User_ID')['Num_Comm_Prev_Month'].apply(lambda x: x.shift(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del comments, comments_timestamp, unique_comments\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = data.groupby('timestamp').agg({\n",
    "    \"User_ID\": [\"nunique\"],\n",
    "    \"Total_Num_User_Months\": [\"mean\", \"max\", \"std\"],\n",
    "})\n",
    "table.columns = [\"_\".join(col) for col in table.columns]\n",
    "table = table.reset_index()\n",
    "\n",
    "data = data.merge(table, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Months_Since_Last_Comp', 'Months_Since_Last_Dis', 'Months_Since_Last_Sub', 'Months_Since_Last_Comment']\n",
    "data['Months_Since_Last_Activity_Mean'] = data[columns].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'Zindi_Joining_Timestamp',\n",
    "    'comment_timestamp',\n",
    "    'comp_timestamp',\n",
    "    'discussion_timestamp',\n",
    "    'sub_timestamp',\n",
    "    'Months_Since_Last_Comp',\n",
    "    'Months_Since_Last_Sub',\n",
    "    'Months_Since_Last_Dis',\n",
    "    'Months_Since_Last_Comment',\n",
    "]\n",
    "\n",
    "for cl in columns:\n",
    "    data[cl] = data[cl]/data['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = data[data['Zindi_Joining_Timestamp'] == 1]\n",
    "time = time.groupby('timestamp')['User_ID'].nunique().to_frame(\"unique_user_count\")\n",
    "time = time.reset_index()\n",
    "\n",
    "data = data.merge(time, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['user_interests_rank'] = data.groupby('timestamp')['user_interests'].apply(\n",
    "    lambda x: x.rank(method = 'dense', ascending = False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259832, 9) (65223, 4)\n",
      "(259832, 81) (65223, 81)\n"
     ]
    }
   ],
   "source": [
    "# data.loc[data['user_interests']==0, 'user_interests'] = np.NaN\n",
    "print(train.shape, test.shape)\n",
    "train, test = data[data['is_train'] == 1], data[data['is_train'] == 0]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train_model(X_train, Y_train, X_eval, Y_eval, cat_cols, params = None):\n",
    "    \n",
    "    if params is None:\n",
    "        params={'verbose' : 0, 'n_estimators' : 10000, 'random_state' : 123, 'learning_rate' : 0.01, 'force_row_wise' : True, 'colsample_bytree' : 0.3}\n",
    "    clf = lgb.LGBMClassifier(**params, importance_type = 'gain', metric = 'auc_mu', num_leaves = 127, min_child_samples = 5)\n",
    "    callbacks = [lgb.early_stopping(500, verbose = 0)]\n",
    "    clf.fit(X_train, Y_train, eval_set=[(X_eval, Y_eval)], callbacks = callbacks)\n",
    "    valid_score = roc_auc_score(Y_eval !='NoActivity', 1 - clf.predict_proba(X_eval)[ : , 1])\n",
    "    best_iteration = clf.booster_.best_iteration\n",
    "    feature_score = clf.feature_importances_\n",
    "        \n",
    "    return clf, valid_score, best_iteration, feature_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv(\"./Train_fe.csv.gz\", compression='gzip')\n",
    "# test.to_csv(\"./Test_fe.csv.gz\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Fold 1 0.9047704034250024 at 607\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Fold 2 0.9040483468365561 at 997\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Fold 3 0.9083226787875357 at 527\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Fold 4 0.9024709412914756 at 805\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Fold 5 0.9081002139555148 at 971\n",
      "The local CV is 0.9055483773006583\n",
      "CPU times: total: 1h 27min 12s\n",
      "Wall time: 22min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "drop_cols = [\n",
    "    'year', 'month', 'Target', 'Sub', 'CompPart', 'Comment', 'Disc',\n",
    "    'is_train', 'timestamp', 'Record', 'Active_Month', 'Total_Num_User_Months',\n",
    "    'user_interests'\n",
    "]\n",
    "cat_cols = list(\n",
    "    set(train.columns[train.dtypes == 'object']) - set(drop_cols) - set(['User_ID'])\n",
    ")\n",
    "num_cols = list(set(train.columns) - set(cat_cols + drop_cols))\n",
    "\n",
    "train_X = train[cat_cols + num_cols]\n",
    "train_X[cat_cols] = train_X[cat_cols].astype('category')\n",
    "train_Y = train['Target']\n",
    "\n",
    "test_X = test[cat_cols + num_cols]\n",
    "test_X[cat_cols] = test_X[cat_cols].astype('category')\n",
    "\n",
    "fold = GroupKFold(n_splits=5)\n",
    "cb_scores, pred_cb, feat_scores = [], [], []\n",
    "for it, (idxT, idxV) in enumerate(\n",
    "        fold.split(train_X, train_Y, groups = train['timestamp'])):\n",
    "    X_train, Y_train = train_X.iloc[idxT], train_Y.iloc[idxT]\n",
    "    X_eval, Y_eval = train_X.iloc[idxV], train_Y.iloc[idxV]\n",
    "    X_test = test_X.copy()\n",
    "\n",
    "    selected_cat_cols = ['Country']\n",
    "    cat_cols_count = [f'{col}_count' for col in selected_cat_cols]\n",
    "    X_train[cat_cols_count] = X_train[selected_cat_cols].copy()\n",
    "    X_eval[cat_cols_count] = X_eval[selected_cat_cols].copy()\n",
    "    X_test[cat_cols_count] = X_test[selected_cat_cols].copy()\n",
    "\n",
    "    encoder = CountEncoder(cols = cat_cols_count + ['User_ID'])\n",
    "    X_train = encoder.fit_transform(X_train, Y_train)\n",
    "    X_eval = encoder.transform(X_eval)\n",
    "    X_test = encoder.transform(X_test)\n",
    "\n",
    "    clf, valid_score, best_iteration, feature_score = train_model(X_train, Y_train, X_eval, Y_eval, cat_cols)\n",
    "    cb_scores.append(valid_score)\n",
    "    pred_cb.append(clf.predict_proba(X_test)[ : , 1])\n",
    "    feat_scores.append(feature_score)\n",
    "    print('Fold {} {} at {}'.format(it + 1, valid_score, best_iteration))\n",
    "\n",
    "weights = cb_scores / sum(np.array(cb_scores))\n",
    "print('The local CV is {}'.format(np.sum(weights * cb_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if LOCAL_TEST_RUN:\n",
    "#     weights=cb_scores/sum(np.array(cb_scores))\n",
    "#     print ('The local CV is {}'.format(np.sum(weights*cb_scores)))\n",
    "\n",
    "#     prediction = np.sum(weights*np.transpose(pred_cb),1)\n",
    "#     from sklearn.metrics import roc_auc_score\n",
    "#     print(\"Test score is {}\".format(roc_auc_score(test['Target']!='NoActivity', 1-prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Num_Comp_Per_Month_trend</td>\n",
       "      <td>10.086937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Num_Sub_Prev_Month</td>\n",
       "      <td>9.341121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Num_Comp_Prev_Month</td>\n",
       "      <td>7.528516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Num_Comp_Per_Month</td>\n",
       "      <td>6.499248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Points</td>\n",
       "      <td>4.767458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Current_Active_Competitions</td>\n",
       "      <td>3.813653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Num_Comm_Prev_Month</td>\n",
       "      <td>3.179021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zindi_Joining_Timestamp</td>\n",
       "      <td>3.172377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Months_Since_Last_Sub</td>\n",
       "      <td>3.091694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Months_Since_Last_Comp</td>\n",
       "      <td>2.829499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Country</td>\n",
       "      <td>2.505466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>comp_timestamp</td>\n",
       "      <td>2.345955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Total_Num_User_Months_std</td>\n",
       "      <td>2.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>user_interests_rank</td>\n",
       "      <td>1.875103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sub_timestamp</td>\n",
       "      <td>1.738800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>User_ID</td>\n",
       "      <td>1.713137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Num_Sub_Prev_Month_momentum</td>\n",
       "      <td>1.631700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Country_count</td>\n",
       "      <td>1.579210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>User_ID_nunique</td>\n",
       "      <td>1.576743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Months_Since_Joining_Zindi</td>\n",
       "      <td>1.452101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Num_Comm_Per_Month</td>\n",
       "      <td>1.449431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Months_Since_Sub_Joining_Zindi</td>\n",
       "      <td>1.395641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Num_Sub_Per_Month</td>\n",
       "      <td>1.324717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>unique_user_count</td>\n",
       "      <td>1.242463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Num_Comm_Per_Month_trend</td>\n",
       "      <td>1.224353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Num_Sub_Per_Month_trend</td>\n",
       "      <td>1.188049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Num_Comp_Prev_Month_momentum</td>\n",
       "      <td>1.016543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Num_Sub_Prev_Month_momentum2</td>\n",
       "      <td>1.005404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Total_Num_User_Months_max</td>\n",
       "      <td>0.994698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Num_Dis_Prev_Month</td>\n",
       "      <td>0.967137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FeatureG_1</td>\n",
       "      <td>0.924644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Successful_Sub_Count_count 10</td>\n",
       "      <td>0.838408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Num_Comp_Prev_Month_momentum2</td>\n",
       "      <td>0.770321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Months_Since_Last_Activity_Mean</td>\n",
       "      <td>0.743410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Total_Num_User_Months_mean</td>\n",
       "      <td>0.697123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>FeatureX</td>\n",
       "      <td>0.692402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Num_Dis_Per_Month</td>\n",
       "      <td>0.682308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Num_Dis_Per_Month_trend</td>\n",
       "      <td>0.677675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Successful_Sub_Count_count 6</td>\n",
       "      <td>0.547465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Months_Since_Last_Comment</td>\n",
       "      <td>0.542344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>year_month</td>\n",
       "      <td>0.524377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PublicRank_rank 11</td>\n",
       "      <td>0.459545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>discussion_timestamp</td>\n",
       "      <td>0.442468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>comment_timestamp</td>\n",
       "      <td>0.439448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Successful_Sub_Count_count 3</td>\n",
       "      <td>0.431902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Successful_Sub_Count_count 8</td>\n",
       "      <td>0.417475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>FeatureY</td>\n",
       "      <td>0.387146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Num_Dis_Prev_Month_momentum</td>\n",
       "      <td>0.381044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Successful_Sub_Count_count 7</td>\n",
       "      <td>0.368310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>FeatureG_0</td>\n",
       "      <td>0.360279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Months_Since_Comment_Joining_Zindi</td>\n",
       "      <td>0.338727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Months_Since_Last_Dis</td>\n",
       "      <td>0.317290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Num_Comm_Prev_Month_momentum</td>\n",
       "      <td>0.300837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Num_Comm_Prev_Month_momentum2</td>\n",
       "      <td>0.299148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>PublicRank_rank 1</td>\n",
       "      <td>0.266509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Months_Since_Dis_Joining_Zindi</td>\n",
       "      <td>0.258652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>FeatureG_3</td>\n",
       "      <td>0.242486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Successful_Sub_Count_count 9</td>\n",
       "      <td>0.240498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Num_Dis_Prev_Month_momentum2</td>\n",
       "      <td>0.231760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Successful_Sub_Count_count 5</td>\n",
       "      <td>0.214589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>PublicRank_rank 10</td>\n",
       "      <td>0.198038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>PublicRank_rank 2</td>\n",
       "      <td>0.190972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Successful_Sub_Count_count 4</td>\n",
       "      <td>0.187377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>PublicRank_rank 5</td>\n",
       "      <td>0.162360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>PublicRank_rank 9</td>\n",
       "      <td>0.149353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>PublicRank_rank 3</td>\n",
       "      <td>0.126587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>PublicRank_rank 8</td>\n",
       "      <td>0.103302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>PublicRank_rank 6</td>\n",
       "      <td>0.101632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>PublicRank_rank 7</td>\n",
       "      <td>0.094021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>PublicRank_rank 4</td>\n",
       "      <td>0.091094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature  importance\n",
       "0             Num_Comp_Per_Month_trend   10.086937\n",
       "1                   Num_Sub_Prev_Month    9.341121\n",
       "2                  Num_Comp_Prev_Month    7.528516\n",
       "3                   Num_Comp_Per_Month    6.499248\n",
       "4                               Points    4.767458\n",
       "5          Current_Active_Competitions    3.813653\n",
       "6                  Num_Comm_Prev_Month    3.179021\n",
       "7              Zindi_Joining_Timestamp    3.172377\n",
       "8                Months_Since_Last_Sub    3.091694\n",
       "9               Months_Since_Last_Comp    2.829499\n",
       "10                             Country    2.505466\n",
       "11                      comp_timestamp    2.345955\n",
       "12           Total_Num_User_Months_std    2.020500\n",
       "13                 user_interests_rank    1.875103\n",
       "14                       sub_timestamp    1.738800\n",
       "15                             User_ID    1.713137\n",
       "16         Num_Sub_Prev_Month_momentum    1.631700\n",
       "17                       Country_count    1.579210\n",
       "18                     User_ID_nunique    1.576743\n",
       "19          Months_Since_Joining_Zindi    1.452101\n",
       "20                  Num_Comm_Per_Month    1.449431\n",
       "21      Months_Since_Sub_Joining_Zindi    1.395641\n",
       "22                   Num_Sub_Per_Month    1.324717\n",
       "23                   unique_user_count    1.242463\n",
       "24            Num_Comm_Per_Month_trend    1.224353\n",
       "25             Num_Sub_Per_Month_trend    1.188049\n",
       "26        Num_Comp_Prev_Month_momentum    1.016543\n",
       "27        Num_Sub_Prev_Month_momentum2    1.005404\n",
       "28           Total_Num_User_Months_max    0.994698\n",
       "29                  Num_Dis_Prev_Month    0.967137\n",
       "30                          FeatureG_1    0.924644\n",
       "31       Successful_Sub_Count_count 10    0.838408\n",
       "32       Num_Comp_Prev_Month_momentum2    0.770321\n",
       "33     Months_Since_Last_Activity_Mean    0.743410\n",
       "34          Total_Num_User_Months_mean    0.697123\n",
       "35                            FeatureX    0.692402\n",
       "36                   Num_Dis_Per_Month    0.682308\n",
       "37             Num_Dis_Per_Month_trend    0.677675\n",
       "38        Successful_Sub_Count_count 6    0.547465\n",
       "39           Months_Since_Last_Comment    0.542344\n",
       "40                          year_month    0.524377\n",
       "41                  PublicRank_rank 11    0.459545\n",
       "42                discussion_timestamp    0.442468\n",
       "43                   comment_timestamp    0.439448\n",
       "44        Successful_Sub_Count_count 3    0.431902\n",
       "45        Successful_Sub_Count_count 8    0.417475\n",
       "46                            FeatureY    0.387146\n",
       "47         Num_Dis_Prev_Month_momentum    0.381044\n",
       "48        Successful_Sub_Count_count 7    0.368310\n",
       "49                          FeatureG_0    0.360279\n",
       "50  Months_Since_Comment_Joining_Zindi    0.338727\n",
       "51               Months_Since_Last_Dis    0.317290\n",
       "52        Num_Comm_Prev_Month_momentum    0.300837\n",
       "53       Num_Comm_Prev_Month_momentum2    0.299148\n",
       "54                   PublicRank_rank 1    0.266509\n",
       "55      Months_Since_Dis_Joining_Zindi    0.258652\n",
       "56                          FeatureG_3    0.242486\n",
       "57        Successful_Sub_Count_count 9    0.240498\n",
       "58        Num_Dis_Prev_Month_momentum2    0.231760\n",
       "59        Successful_Sub_Count_count 5    0.214589\n",
       "60                  PublicRank_rank 10    0.198038\n",
       "61                   PublicRank_rank 2    0.190972\n",
       "62        Successful_Sub_Count_count 4    0.187377\n",
       "63                   PublicRank_rank 5    0.162360\n",
       "64                   PublicRank_rank 9    0.149353\n",
       "65                   PublicRank_rank 3    0.126587\n",
       "66                   PublicRank_rank 8    0.103302\n",
       "67                   PublicRank_rank 6    0.101632\n",
       "68                   PublicRank_rank 7    0.094021\n",
       "69                   PublicRank_rank 4    0.091094"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureImp = pd.DataFrame({'feature' : X_train.columns, 'importance' : np.mean(np.array(feat_scores), 0)})\n",
    "featureImp = featureImp.sort_values('importance', ascending = False)\n",
    "featureImp['importance'] = featureImp['importance'] * 100 / featureImp['importance'].sum()\n",
    "featureImp.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Target'] = np.sum(weights * np.transpose(pred_cb), 1)\n",
    "test['Target'] = 1 - test['Target']\n",
    "test['UserMonthYear'] = test['User_ID'] + \"_\" + test['month'].astype(str) + \"_\" + test['year'].astype(str)\n",
    "test[['UserMonthYear', 'Target']].to_csv('output.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserMonthYear</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ID_000VV0KM_1_4</td>\n",
       "      <td>0.014868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ID_000VV0KM_2_4</td>\n",
       "      <td>0.014797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ID_000VV0KM_3_4</td>\n",
       "      <td>0.011047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ID_003OCIYO_1_4</td>\n",
       "      <td>0.328817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ID_003OCIYO_2_4</td>\n",
       "      <td>0.017720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325041</th>\n",
       "      <td>ID_ZZVPF22K_2_4</td>\n",
       "      <td>0.152806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325042</th>\n",
       "      <td>ID_ZZVPF22K_3_4</td>\n",
       "      <td>0.110334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325052</th>\n",
       "      <td>ID_ZZXDLYXB_1_4</td>\n",
       "      <td>0.008596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325053</th>\n",
       "      <td>ID_ZZXDLYXB_2_4</td>\n",
       "      <td>0.007822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325054</th>\n",
       "      <td>ID_ZZXDLYXB_3_4</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65223 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          UserMonthYear    Target\n",
       "13      ID_000VV0KM_1_4  0.014868\n",
       "14      ID_000VV0KM_2_4  0.014797\n",
       "15      ID_000VV0KM_3_4  0.011047\n",
       "16      ID_003OCIYO_1_4  0.328817\n",
       "17      ID_003OCIYO_2_4  0.017720\n",
       "...                 ...       ...\n",
       "325041  ID_ZZVPF22K_2_4  0.152806\n",
       "325042  ID_ZZVPF22K_3_4  0.110334\n",
       "325052  ID_ZZXDLYXB_1_4  0.008596\n",
       "325053  ID_ZZXDLYXB_2_4  0.007822\n",
       "325054  ID_ZZXDLYXB_3_4  0.007207\n",
       "\n",
       "[65223 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[['UserMonthYear', 'Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
