{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Loading-train-data\" data-toc-modified-id=\"Loading-train-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Loading train data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Merging-train-and-test-data\" data-toc-modified-id=\"Merging-train-and-test-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Merging train and test data</a></span></li><li><span><a href=\"#Merging-user-data\" data-toc-modified-id=\"Merging-user-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Merging user data</a></span></li><li><span><a href=\"#Competitions-based-features\" data-toc-modified-id=\"Competitions-based-features-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Competitions based features</a></span></li><li><span><a href=\"#Competitions-data\" data-toc-modified-id=\"Competitions-data-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Competitions data</a></span></li><li><span><a href=\"#Time-based-competitions-features\" data-toc-modified-id=\"Time-based-competitions-features-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Time based competitions features</a></span></li><li><span><a href=\"#Current-active-competitions-feature\" data-toc-modified-id=\"Current-active-competitions-feature-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Current active competitions feature</a></span></li><li><span><a href=\"#User-Interests-Feature\" data-toc-modified-id=\"User-Interests-Feature-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>User Interests Feature</a></span></li><li><span><a href=\"#Submissions-based-features\" data-toc-modified-id=\"Submissions-based-features-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Submissions based features</a></span></li><li><span><a href=\"#Discussion-based-features\" data-toc-modified-id=\"Discussion-based-features-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Discussion based features</a></span></li><li><span><a href=\"#Comments-based-features\" data-toc-modified-id=\"Comments-based-features-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>Comments based features</a></span></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Modeling</a></span></li><li><span><a href=\"#Submission\" data-toc-modified-id=\"Submission-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Submission</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ast\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from catboost import CatBoostClassifier\n",
    "from category_encoders import CountEncoder\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams[\"axes.labelsize\"] = 16\n",
    "plt.rcParams[\"xtick.labelsize\"] = 14\n",
    "plt.rcParams[\"ytick.labelsize\"] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Config:\n",
    "#     LAG = 3\n",
    "#     VER = f'final_sub_v1'\n",
    "#     OUTPUT_DIR = '.'\n",
    "#     DATA_DIR = '.'\n",
    "#     DEBUG = True\n",
    "#     N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL_TEST_RUN = False\n",
    "seed = 0\n",
    "# def seed_everything(seed=0):\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(df):\n",
    "    target = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['CompPart'] == 1:\n",
    "            target.append('CompPart')\n",
    "            continue\n",
    "        elif row['Sub'] == 1 or row['Comment'] == 1 or row['Disc'] == 1:\n",
    "            target.append('Sub')\n",
    "            continue\n",
    "        else:\n",
    "            target.append('NoActivity')\n",
    "        \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259832, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>CompPart</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sub</th>\n",
       "      <th>Disc</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_XI7BAR4Y</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NoActivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_XI7BAR4Y</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NoActivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_XI7BAR4Y</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NoActivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_XI7BAR4Y</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NoActivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_XI7BAR4Y</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NoActivity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       User_ID  month  year  CompPart  Comment  Sub  Disc      Target\n",
       "0  ID_XI7BAR4Y      8     3         0        0    0     0  NoActivity\n",
       "1  ID_XI7BAR4Y      8     2         0        0    0     0  NoActivity\n",
       "2  ID_XI7BAR4Y      9     2         0        0    0     0  NoActivity\n",
       "3  ID_XI7BAR4Y      9     3         0        0    0     0  NoActivity\n",
       "4  ID_XI7BAR4Y     10     3         0        0    0     0  NoActivity"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./Train.csv\", index_col=None)\n",
    "print(train.shape)\n",
    "train['Target'] = target(train)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65223, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_H1ELY25E</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_H1ELY25E</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_H1ELY25E</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_463Q2BCO</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_463Q2BCO</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       User_ID  month  year\n",
       "0  ID_H1ELY25E      1     4\n",
       "1  ID_H1ELY25E      2     4\n",
       "2  ID_H1ELY25E      3     4\n",
       "3  ID_463Q2BCO      1     4\n",
       "4  ID_463Q2BCO      2     4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"./Test.csv\", index_col=None)\n",
    "print(test.shape)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_timestamp(df):\n",
    "    year_month = df['year'].astype(str) + \\\n",
    "        df['month'].apply(lambda x: str(x).zfill(2))\n",
    "    df['year_month'] = year_month.astype(int)\n",
    "    df = df.sort_values(by='year_month').reset_index(drop=True)\n",
    "    df['timestamp'] = np.arange(1, len(df) + 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "\n",
    "data = train.append(test, ignore_index=True)\n",
    "timestamp = data[['year', 'month']].drop_duplicates()\n",
    "timestamp = define_timestamp(timestamp)\n",
    "data = data.merge(timestamp, how='left')\n",
    "all_timestamps = data[['User_ID', 'timestamp', 'year', 'month']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "data = data.sort_values(by='timestamp').reset_index(drop=True)\n",
    "data['Record'] = 1\n",
    "data['Total_Num_User_Months'] = data.groupby('User_ID')['Record'].apply(lambda x: x.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>FeatureX</th>\n",
       "      <th>Country</th>\n",
       "      <th>FeatureY</th>\n",
       "      <th>Points</th>\n",
       "      <th>Zindi_Joining_Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_N5LTBAPU</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_DMRM</td>\n",
       "      <td>1</td>\n",
       "      <td>group 3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_CLSFQB0S</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_Q02</td>\n",
       "      <td>3</td>\n",
       "      <td>group 3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_RE6T58Y4</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_Q02</td>\n",
       "      <td>0</td>\n",
       "      <td>group 3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_XJQQRJV3</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_Z8BI</td>\n",
       "      <td>0</td>\n",
       "      <td>group 3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_1JHU6A8S</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_Q02</td>\n",
       "      <td>3</td>\n",
       "      <td>group 3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       User_ID  FeatureX  Country  FeatureY   Points  Zindi_Joining_Timestamp\n",
       "0  ID_N5LTBAPU         0  ID_DMRM         1  group 3                       13\n",
       "1  ID_CLSFQB0S         0   ID_Q02         3  group 3                        2\n",
       "2  ID_RE6T58Y4         0   ID_Q02         0  group 3                       21\n",
       "3  ID_XJQQRJV3         0  ID_Z8BI         0  group 3                       18\n",
       "4  ID_1JHU6A8S         0   ID_Q02         3  group 3                       19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(\"./Users.csv\", index_col=None)\n",
    "users.columns = ['User_ID', 'FeatureX', 'Country', 'FeatureY', 'Points', 'year', 'month', 'dayofweek']\n",
    "users = users.merge(timestamp, how='left')\n",
    "users = users.rename(columns={\"timestamp\": \"Zindi_Joining_Timestamp\"})\n",
    "users.drop(['dayofweek', 'year', 'month', 'year_month'], axis=1, inplace=True)\n",
    "users.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(users, how='left')\n",
    "\n",
    "columns = ['FeatureX', 'Country', 'FeatureY', 'Points']\n",
    "data[columns] = data[columns].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competitions based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_data = pd.read_csv(\"./CompetitionPartipation.csv\", index_col=None)\n",
    "competition_data.columns = [\n",
    "    'CompID', 'User_ID', 'PublicRank', 'Successful_Sub_Count',\n",
    "    'year', 'month', 'dayofweek'\n",
    "]\n",
    "    \n",
    "competition_timestamp = competition_data.merge(timestamp, how='left')\n",
    "competition_timestamp = competition_timestamp[[\n",
    "    'User_ID', 'month', 'year', 'timestamp'\n",
    "]].drop_duplicates()\n",
    "competition_timestamp.columns = [\n",
    "    'User_ID', 'month', 'year', 'comp_timestamp'\n",
    "]\n",
    "data = data.merge(competition_timestamp, how='left')\n",
    "\n",
    "data = data.sort_values(by='timestamp').reset_index(drop=True)\n",
    "data['comp_timestamp'] = data.groupby('User_ID')['comp_timestamp'].apply(lambda x: x.ffill().shift())\n",
    "data['Months_Since_Last_Comp'] = data['timestamp'] - data['comp_timestamp']\n",
    "data['Months_Since_Joining_Zindi'] = data['comp_timestamp'] - data['Zindi_Joining_Timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competitions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitions = pd.read_csv(\"./Competitions.csv\", index_col=None, skipinitialspace=True)\n",
    "competitions['CompEndTime Year'] = [\n",
    "    int(val) if val != 'not mapped' else 999 \\\n",
    "    for val in competitions['CompEndTime Year']\n",
    "]\n",
    "competitions['FeatureC'] = competitions['FeatureC'].fillna(-1).astype(np.int8)\n",
    "competitions = competitions.merge(\n",
    "    timestamp,\n",
    "    left_on=['CompStartTime Year', 'CompStartTime Month'],\n",
    "    right_on=['year', 'month'],\n",
    "    how='left')\n",
    "competitions = competitions.rename(columns={\n",
    "    'timestamp': 'comp_start_timestamp',\n",
    "})\n",
    "competitions.drop(['year', 'month', 'year_month'], axis=1, inplace=True)\n",
    "competitions = competitions.merge(\n",
    "    timestamp,\n",
    "    left_on=['CompEndTime Year', 'CompEndTime Month'],\n",
    "    right_on=['year', 'month'],\n",
    "    how='left')\n",
    "competitions = competitions.rename(columns={\n",
    "    'timestamp': 'comp_end_timestamp',\n",
    "})\n",
    "competitions['comp_end_timestamp'] = competitions['comp_end_timestamp'].fillna(99)\n",
    "competitions.drop(['year', 'month', 'year_month'], axis=1, inplace=True)\n",
    "competitions['comp_duration'] = competitions['comp_end_timestamp'] - competitions['comp_start_timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['FeatureA', 'FeatureB', 'FeatureE']:\n",
    "    competitions[column] = competitions[column].map(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = competitions[['CompID']].copy()\n",
    "for column in ['FeatureA', 'FeatureB', 'FeatureC', 'FeatureD', 'FeatureE']:\n",
    "    table = competitions[['CompID', column]].explode(column=[column])\n",
    "    table[column] = table[column].fillna('empty')\n",
    "    table['count'] = 1\n",
    "\n",
    "    table = table.pivot_table(\n",
    "        index='CompID', \n",
    "        columns=column,\n",
    "        values='count',\n",
    "        aggfunc='count'\n",
    "    )\n",
    "    table.columns = [table.columns.name + \"_\" + str(cl) for cl in table.columns]\n",
    "    table = table.reset_index()\n",
    "    features = features.merge(table, how='left')\n",
    "features = features.fillna(0)\n",
    "features = features.merge(competitions[['CompID', 'comp_start_timestamp']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time based competitions features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 2005.43it/s]\n"
     ]
    }
   ],
   "source": [
    "timestamp_inds = []\n",
    "competitions_inds = []\n",
    "\n",
    "for t in tqdm(timestamp.timestamp):\n",
    "    current_competition = competitions.CompID[\n",
    "        (t>=competitions.comp_start_timestamp) & (t<=competitions.comp_end_timestamp)\n",
    "    ]\n",
    "    timestamp_inds.extend([t] * len(current_competition))\n",
    "    competitions_inds.extend(current_competition)\n",
    "\n",
    "timestamp_competition = pd.DataFrame({\n",
    "    \"timestamp\": timestamp_inds,\n",
    "    \"CompID\": competitions_inds\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current active competitions feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_competition = competition_data.merge(timestamp, how='left')\n",
    "current_competition = current_competition.rename(columns={\"timestamp\": \"comp_timestamp\"})\n",
    "current_competition = current_competition[\n",
    "    ['User_ID', 'CompID', 'comp_timestamp']\n",
    "].merge(competitions[\n",
    "    ['CompID', 'comp_start_timestamp', 'comp_end_timestamp']\n",
    "], how='left')\n",
    "current_competition = current_competition[current_competition['comp_end_timestamp']!=99].reset_index(drop=True)\n",
    "current_competition = all_timestamps.merge(current_competition, how='left')\n",
    "\n",
    "current_competition['Current_Active_Competitions'] = (\n",
    "    (current_competition['timestamp'] > current_competition['comp_timestamp']) &\n",
    "    (current_competition['timestamp'] <= current_competition['comp_end_timestamp'])\n",
    ").astype(np.int8)\n",
    "\n",
    "current_competition = current_competition.groupby(['User_ID', 'timestamp'])['Current_Active_Competitions'].sum()\n",
    "current_competition = current_competition.reset_index()\n",
    "\n",
    "data = data.merge(current_competition, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Interests Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FeatureA_1', 'FeatureA_2', 'FeatureA_3', 'FeatureA_4', 'FeatureA_5',\n",
      "       'FeatureA_6', 'FeatureA_7', 'FeatureA_8', 'FeatureA_9', 'FeatureA_10',\n",
      "       'FeatureA_empty', 'FeatureB_5', 'FeatureB_6', 'FeatureB_7',\n",
      "       'FeatureB_8', 'FeatureB_9', 'FeatureB_10', 'FeatureB_12', 'FeatureB_14',\n",
      "       'FeatureB_15', 'FeatureB_16', 'FeatureB_empty', 'FeatureC_-1',\n",
      "       'FeatureC_1', 'FeatureC_2', 'FeatureC_3', 'FeatureC_4', 'FeatureC_5',\n",
      "       'FeatureC_6', 'FeatureC_7', 'FeatureC_8', 'FeatureC_9', 'FeatureC_10',\n",
      "       'FeatureC_11', 'FeatureC_12', 'FeatureC_13', 'FeatureC_14',\n",
      "       'FeatureC_15', 'FeatureC_16', 'FeatureC_17', 'FeatureC_18',\n",
      "       'FeatureC_19', 'FeatureC_20', 'FeatureC_21', 'FeatureC_22',\n",
      "       'FeatureC_23', 'FeatureC_24', 'FeatureC_25', 'FeatureC_26',\n",
      "       'FeatureC_27', 'FeatureC_28', 'FeatureC_29', 'FeatureC_30',\n",
      "       'FeatureC_31', 'FeatureC_32', 'FeatureC_33', 'FeatureC_34',\n",
      "       'FeatureC_35', 'FeatureC_36', 'FeatureC_37', 'FeatureD_1', 'FeatureD_2',\n",
      "       'FeatureD_3', 'FeatureE_1', 'FeatureE_2', 'FeatureE_3', 'FeatureE_4',\n",
      "       'FeatureE_5', 'FeatureE_6', 'FeatureE_7', 'FeatureE_8', 'FeatureE_9',\n",
      "       'FeatureE_10', 'FeatureE_empty'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [06:41<00:00,  5.43s/it]\n"
     ]
    }
   ],
   "source": [
    "timestamp_competition = timestamp_competition.merge(features, how='left')\n",
    "timestamp_competition.drop(['comp_start_timestamp', 'CompID'], axis=1, inplace=True)\n",
    "timestamp_competition = timestamp_competition.groupby('timestamp').agg(np.sum).reset_index()\n",
    "timestamp_competition = timestamp_competition.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "competition_timestamp = competition_data.merge(timestamp, how='left')\n",
    "usr_features = competition_timestamp[['User_ID', 'CompID', 'timestamp']].merge(features, how='left')\n",
    "usr_features = usr_features.drop(['CompID', 'comp_start_timestamp'], axis=1)\n",
    "usr_features = usr_features.groupby(['User_ID', 'timestamp']).agg(np.sum)#.groupby(level=0).cumsum()\n",
    "usr_features = usr_features.reset_index()\n",
    "usr_features = all_timestamps.merge(usr_features, how='left')\n",
    "columns = usr_features.columns[4:]\n",
    "print(columns)\n",
    "\n",
    "usr_features = usr_features.sort_values(by='timestamp').reset_index(drop=True)\n",
    "for cl in tqdm(columns):\n",
    "    usr_features[cl] = usr_features.groupby('User_ID')[cl].apply(lambda x: x.ffill())\n",
    "\n",
    "usr_features = usr_features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "timestamp_inds = []\n",
    "usr_inds = []\n",
    "user_interests = []\n",
    "\n",
    "for t in timestamp_competition['timestamp']:\n",
    "    if t == 1:\n",
    "        continue\n",
    "    usr_filtered = usr_features[usr_features['timestamp']==t-1]\n",
    "    timestamp_inds.extend([t]*len(usr_filtered))\n",
    "    usr_inds.extend(usr_filtered.pop('User_ID'))\n",
    "    \n",
    "    comp_filtered = timestamp_competition[timestamp_competition['timestamp']==t]\n",
    "    usr_filtered.drop(['timestamp', 'year', 'month'], axis=1, inplace=True)\n",
    "    comp_filtered.drop('timestamp', axis=1, inplace=True)\n",
    "    \n",
    "    interests = np.matmul(usr_filtered.values, comp_filtered.values.T).flatten()\n",
    "#     interests = cosine_similarity(usr_filtered.values, comp_filtered.values).flatten()\n",
    "    user_interests.extend(interests)\n",
    "\n",
    "usr_interest_f = pd.DataFrame({\n",
    "    \"timestamp\": timestamp_inds,\n",
    "    \"User_ID\": usr_inds,\n",
    "    \"user_interests\": user_interests\n",
    "})\n",
    "\n",
    "data = data.merge(usr_interest_f, how='left')\n",
    "data = data.sort_values(by='timestamp').reset_index(drop=True)\n",
    "data['user_interests'] = data.groupby('User_ID')['user_interests'].apply(lambda x: x.ffill())\n",
    "data['user_interests'] = data['user_interests'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = competition_data.groupby(['User_ID', 'year', 'month'])['CompID'].nunique()\n",
    "history = history.reset_index()\n",
    "history.columns = [*history.columns[:-1]] + ['Num_Comp_Prev_Month']\n",
    "\n",
    "data = data.merge(history, how='left')\n",
    "data = data.sort_values(by=['User_ID', 'timestamp']).reset_index(drop=True)\n",
    "data['Num_Comp_Prev_Month'] = data['Num_Comp_Prev_Month'].fillna(0)\n",
    "data['Num_Comp_Per_Month'] = data.groupby('User_ID')['Num_Comp_Prev_Month'].cumsum()\n",
    "data['Num_Comp_Per_Month_trend'] = data['Num_Comp_Per_Month']/data['Total_Num_User_Months']\n",
    "data['Num_Comp_Per_Month_trend'] = data.groupby('User_ID')['Num_Comp_Per_Month_trend'].apply(lambda x: x.shift())\n",
    "data['Num_Comp_Per_Month'] = data['Num_Comp_Per_Month']/(data['timestamp'].max() - data['Zindi_Joining_Timestamp'])\n",
    "data['Num_Comp_Per_Month'] = data.groupby('User_ID')['Num_Comp_Per_Month'].apply(lambda x: x.shift())\n",
    "\n",
    "data['Num_Comp_Prev_Month'] = data.groupby('User_ID')['Num_Comp_Prev_Month'].apply(lambda x: x.shift())\n",
    "data['Num_Comp_Prev_Month_momentum'] = data['Num_Comp_Prev_Month'] - data.groupby('User_ID')['Num_Comp_Prev_Month'].apply(lambda x: x.shift(1))\n",
    "data['Num_Comp_Prev_Month_momentum2'] = data['Num_Comp_Prev_Month'] - data.groupby('User_ID')['Num_Comp_Prev_Month'].apply(lambda x: x.shift(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = competition_data.groupby(['User_ID', 'year', 'month', 'PublicRank'])['CompID'] \\\n",
    "    .nunique().unstack('PublicRank').apply(lambda x: x/x.sum(), axis=1)\n",
    "col_names = [table.columns.name + \"_\" + str(cl) for cl in table.columns]\n",
    "table.columns = col_names\n",
    "table = table.fillna(0)\n",
    "table = table.reset_index()\n",
    "\n",
    "table = all_timestamps.merge(table, how='left')\n",
    "table = table.sort_values(by='timestamp').reset_index(drop=True)\n",
    "for col in col_names:\n",
    "    table[col] = table.groupby('User_ID')[col].apply(lambda x: x.cumsum().ffill().shift())\n",
    "    \n",
    "data = data.merge(table, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = competition_data.groupby(['User_ID', 'year', 'month', 'Successful_Sub_Count'])['CompID'].nunique().unstack('Successful_Sub_Count').apply(lambda x: x/x.sum(), axis=1)\n",
    "col_names = [table.columns.name + \"_\" + str(col) for col in table.columns]\n",
    "table.columns = col_names\n",
    "table = table.fillna(0)\n",
    "table = table.reset_index()\n",
    "\n",
    "table = all_timestamps.merge(table, how='left')\n",
    "table = table.sort_values(by='timestamp').reset_index(drop=True)\n",
    "for col in col_names:\n",
    "    table[col] = table.groupby('User_ID')[col].apply(lambda x: x.cumsum().ffill().shift())\n",
    "    \n",
    "data = data.merge(table, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del competition_data, competition_timestamp, history\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"./Submissions.csv\", index_col=None)\n",
    "submission.columns = ['User_ID', 'FeatureG', 'CompID', 'year', 'month', 'dayofweek']\n",
    "    \n",
    "submission_timestamp = submission.merge(timestamp, how='left')\n",
    "submission_timestamp = submission_timestamp[['User_ID', 'month', 'year', 'timestamp']].drop_duplicates()\n",
    "submission_timestamp.columns = ['User_ID', 'month', 'year', 'sub_timestamp']\n",
    "data = data.merge(submission_timestamp, how='left')\n",
    "\n",
    "data = data.sort_values(by='timestamp').reset_index(drop=True)\n",
    "data['sub_timestamp'] = data.groupby('User_ID')['sub_timestamp'].apply(lambda x: x.ffill().shift())\n",
    "data['Months_Since_Last_Sub'] = data['timestamp'] - data['sub_timestamp']\n",
    "data['Months_Since_Sub_Joining_Zindi'] = data['sub_timestamp'] - data['Zindi_Joining_Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_submission = submission.groupby(['User_ID', 'year', 'month']).agg({'CompID': ['nunique', 'count']})\n",
    "unique_submission.columns = [\"_\".join(col) for col in unique_submission.columns]\n",
    "unique_submission['Sub_Per_Comp'] = unique_submission['CompID_nunique']/unique_submission['CompID_count']\n",
    "unique_submission.drop(['CompID_nunique', 'CompID_count'], axis=1, inplace=True)\n",
    "unique_submission = unique_submission.reset_index()\n",
    "unique_submission.columns = [*unique_submission.columns[:-1]] + ['Num_Sub_Prev_Month']\n",
    "\n",
    "data = data.merge(unique_submission, how='left')\n",
    "data = data.sort_values(by=['User_ID', 'timestamp']).reset_index(drop=True)\n",
    "data['Num_Sub_Prev_Month'] = data['Num_Sub_Prev_Month'].fillna(0)\n",
    "data['Num_Sub_Per_Month'] = data.groupby('User_ID')['Num_Sub_Prev_Month'].cumsum()\n",
    "data['Num_Sub_Per_Month_trend'] = data['Num_Sub_Per_Month']/data['Total_Num_User_Months']\n",
    "data['Num_Sub_Per_Month_trend'] = data.groupby('User_ID')['Num_Sub_Per_Month_trend'].apply(lambda x: x.shift())\n",
    "data['Num_Sub_Per_Month'] = data['Num_Sub_Per_Month']/(data['timestamp'].max() - data['Zindi_Joining_Timestamp'])\n",
    "data['Num_Sub_Per_Month'] = data.groupby('User_ID')['Num_Sub_Per_Month'].apply(lambda x: x.shift())\n",
    "\n",
    "data['Num_Sub_Prev_Month'] = data.groupby('User_ID')['Num_Sub_Prev_Month'].apply(lambda x: x.shift())\n",
    "data['Num_Sub_Prev_Month_momentum'] = data['Num_Sub_Prev_Month'] - data.groupby('User_ID')['Num_Sub_Prev_Month'].apply(lambda x: x.shift(1))\n",
    "data['Num_Sub_Prev_Month_momentum2'] = data['Num_Sub_Prev_Month'] - data.groupby('User_ID')['Num_Sub_Prev_Month'].apply(lambda x: x.shift(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User_ID', 'FeatureG', 'CompID', 'year', 'month', 'dayofweek'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = submission.groupby(['User_ID', 'year', 'month', 'FeatureG'])['CompID'].nunique().unstack('FeatureG')#.apply(lambda x: x/x.sum(), axis=1)\n",
    "col_names = [table.columns.name + \"_\" + str(col) for col in table.columns]\n",
    "table.columns = col_names\n",
    "table = table.fillna(0)\n",
    "table = table.reset_index()\n",
    "\n",
    "all_timestamps = data[['User_ID', 'timestamp', 'year', 'month']].drop_duplicates().reset_index(drop=True)\n",
    "table = all_timestamps.merge(table, how='left')\n",
    "table = table.sort_values(by='timestamp').reset_index(drop=True)\n",
    "for col in col_names:\n",
    "    table[col] = table.groupby('User_ID')[col].apply(lambda x: x.ffill().shift())\n",
    "    \n",
    "data = data.merge(table, how='left')\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del submission, submission_timestamp, unique_submission\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_dis = pd.read_csv(\"./Discussions.csv\", index_col=None)\n",
    "usr_dis.columns = ['FeatureF', 'year', 'month', 'dayofweek', 'DiscID', 'User_ID']\n",
    "    \n",
    "usr_dis_timestamp = usr_dis.merge(timestamp, how='left')\n",
    "usr_dis_timestamp = usr_dis_timestamp[['User_ID', 'month', 'year', 'timestamp']].drop_duplicates()\n",
    "usr_dis_timestamp.columns = ['User_ID', 'month', 'year', 'discussion_timestamp']\n",
    "data = data.merge(usr_dis_timestamp, how='left')\n",
    "\n",
    "data = data.sort_values(by='timestamp').reset_index(drop=True)\n",
    "data['discussion_timestamp'] = data.groupby('User_ID')['discussion_timestamp'].apply(lambda x: x.ffill().shift())\n",
    "data['Months_Since_Last_Dis'] = data['timestamp'] - data['discussion_timestamp']\n",
    "data['Months_Since_Dis_Joining_Zindi'] = data['discussion_timestamp'] - data['Zindi_Joining_Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_hist = usr_dis.groupby(['User_ID', 'year', 'month'])['DiscID'].nunique()\n",
    "dis_hist = dis_hist.reset_index()\n",
    "dis_hist.columns = [*dis_hist.columns[:-1]] + ['Num_Dis_Prev_Month']\n",
    "\n",
    "data = data.merge(dis_hist, how='left')\n",
    "data = data.sort_values(by=['User_ID', 'timestamp']).reset_index(drop=True)\n",
    "data['Num_Dis_Prev_Month'] = data['Num_Dis_Prev_Month'].fillna(0)\n",
    "data['Num_Dis_Per_Month'] = data.groupby('User_ID')['Num_Dis_Prev_Month'].cumsum()\n",
    "data['Num_Dis_Per_Month_trend'] = data['Num_Dis_Per_Month']/data['Total_Num_User_Months']\n",
    "data['Num_Dis_Per_Month_trend'] = data.groupby('User_ID')['Num_Dis_Per_Month_trend'].apply(lambda x: x.shift())\n",
    "data['Num_Dis_Per_Month'] = data['Num_Dis_Per_Month']/(data['timestamp'].max() - data['Zindi_Joining_Timestamp'])\n",
    "data['Num_Dis_Per_Month'] = data.groupby('User_ID')['Num_Dis_Per_Month'].apply(lambda x: x.shift())\n",
    "\n",
    "data['Num_Dis_Prev_Month'] = data.groupby('User_ID')['Num_Dis_Prev_Month'].apply(lambda x: x.shift())\n",
    "data['Num_Dis_Prev_Month_momentum'] = data['Num_Dis_Prev_Month'] - data.groupby('User_ID')['Num_Dis_Prev_Month'].apply(lambda x: x.shift(1))\n",
    "data['Num_Dis_Prev_Month_momentum2'] = data['Num_Dis_Prev_Month'] - data.groupby('User_ID')['Num_Dis_Prev_Month'].apply(lambda x: x.shift(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del usr_dis, usr_dis_timestamp, dis_hist\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_comments = pd.read_csv(\"./Comments.csv\", index_col=None)\n",
    "usr_comments.columns = ['User_ID', 'year', 'month', 'dayofweek']\n",
    "usr_comments['CommID'] = np.arange(len(usr_comments))\n",
    "    \n",
    "usr_comm_timestamp = usr_comments.merge(timestamp, how='left')\n",
    "usr_comm_timestamp = usr_comm_timestamp[['User_ID', 'month', 'year', 'timestamp']].drop_duplicates()\n",
    "usr_comm_timestamp.columns = ['User_ID', 'month', 'year', 'comment_timestamp']\n",
    "data = data.merge(usr_comm_timestamp, how='left')\n",
    "\n",
    "data = data.sort_values(by='timestamp').reset_index(drop=True)\n",
    "data['comment_timestamp'] = data.groupby('User_ID')['comment_timestamp'].apply(lambda x: x.ffill().shift())\n",
    "data['Months_Since_Last_Comment'] = data['timestamp'] - data['comment_timestamp']\n",
    "data['Months_Since_Comment_Joining_Zindi'] = data['comment_timestamp'] - data['Zindi_Joining_Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_hist = usr_comments.groupby(['User_ID', 'year', 'month'])['CommID'].nunique()\n",
    "comm_hist = comm_hist.reset_index()\n",
    "comm_hist.columns = [*comm_hist.columns[:-1]] + ['Num_Comm_Prev_Month']\n",
    "\n",
    "data = data.merge(comm_hist, how='left')\n",
    "data = data.sort_values(by=['User_ID', 'timestamp']).reset_index(drop=True)\n",
    "data['Num_Comm_Prev_Month'] = data['Num_Comm_Prev_Month'].fillna(0)\n",
    "data['Num_Comm_Per_Month'] = data.groupby('User_ID')['Num_Comm_Prev_Month'].cumsum()\n",
    "data['Num_Comm_Per_Month_trend'] = data['Num_Comm_Per_Month']/data['Total_Num_User_Months']\n",
    "data['Num_Comm_Per_Month_trend'] = data.groupby('User_ID')['Num_Comm_Per_Month_trend'].apply(lambda x: x.shift())\n",
    "data['Num_Comm_Per_Month'] = data['Num_Comm_Per_Month']/(data['timestamp'].max() - data['Zindi_Joining_Timestamp'])\n",
    "data['Num_Comm_Per_Month'] = data.groupby('User_ID')['Num_Comm_Per_Month'].apply(lambda x: x.shift())\n",
    "\n",
    "data['Num_Comm_Prev_Month'] = data.groupby('User_ID')['Num_Comm_Prev_Month'].apply(lambda x: x.shift())\n",
    "data['Num_Comm_Prev_Month_momentum'] = data['Num_Comm_Prev_Month'] - data.groupby('User_ID')['Num_Comm_Prev_Month'].apply(lambda x: x.shift(1))\n",
    "data['Num_Comm_Prev_Month_momentum2'] = data['Num_Comm_Prev_Month'] - data.groupby('User_ID')['Num_Comm_Prev_Month'].apply(lambda x: x.shift(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del usr_comments, usr_comm_timestamp, comm_hist\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data.groupby('timestamp').agg({\n",
    "    \"User_ID\": [\"nunique\"],\n",
    "    \"Total_Num_User_Months\": [\"mean\", \"max\", \"std\"],\n",
    "})\n",
    "tmp.columns = [\"_\".join(col) for col in tmp.columns]\n",
    "tmp = tmp.reset_index()\n",
    "\n",
    "data = data.merge(tmp, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_cols = ['Months_Since_Last_Comp', 'Months_Since_Last_Dis', 'Months_Since_Last_Sub', 'Months_Since_Last_Comment']\n",
    "data['Months_Since_Last_Activity_Mean'] = data[sel_cols].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cols = [\n",
    "    'Zindi_Joining_Timestamp',\n",
    "    'comment_timestamp',\n",
    "    'comp_timestamp',\n",
    "    'discussion_timestamp',\n",
    "    'sub_timestamp',\n",
    "    'Months_Since_Last_Comp',\n",
    "    'Months_Since_Last_Sub',\n",
    "    'Months_Since_Last_Dis',\n",
    "    'Months_Since_Last_Comment',\n",
    "]\n",
    "\n",
    "for col in time_cols:\n",
    "    data[col] = data[col]/data['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_time = data[data['Zindi_Joining_Timestamp']==1]\n",
    "tmp_time = tmp_time.groupby('timestamp')['User_ID'].nunique().to_frame(\"unique_user_count\")\n",
    "tmp_time = tmp_time.reset_index()\n",
    "\n",
    "data = data.merge(tmp_time, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['user_interests_rank'] = data.groupby('timestamp')['user_interests'].apply(lambda x: \n",
    "                                                                                      x.rank(method='dense', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259832, 9) (65223, 4)\n",
      "(259832, 81) (65223, 81)\n"
     ]
    }
   ],
   "source": [
    "# data.loc[data['user_interests']==0, 'user_interests'] = np.NaN\n",
    "print(train.shape, test.shape)\n",
    "train, test = data[data['is_train']==1], data[data['is_train']==0]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df_trainX, df_trainY, df_evalX, df_evalY, cat_cols, model_name='CAT', params=None):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    if model_name == 'CAT':\n",
    "        if params is None:\n",
    "            params={'n_estimators':10000,'random_state':123,'cat_features':cat_cols}\n",
    "        clf=CatBoostClassifier(**params,early_stopping_rounds=50,eval_metric='AUC')\n",
    "        clf.fit(df_trainX,df_trainY,eval_set=(df_evalX,df_evalY),plot=False, verbose=50)\n",
    "        valid_score = clf.get_best_score().get('validation').get('AUC')\n",
    "        best_iteration = clf.get_best_iteration()\n",
    "        feature_score = clf.get_feature_importance()\n",
    "    elif model_name == 'LGB':\n",
    "        if params is None:\n",
    "            params={'verbose':0,'n_estimators':10000,'random_state':123,'learning_rate':0.01,'force_row_wise':True,'colsample_bytree':0.3}\n",
    "        clf = lgb.LGBMClassifier(**params, importance_type='gain', metric='auc_mu', num_leaves=127, min_child_samples=5)\n",
    "        callbacks = [lgb.early_stopping(500, verbose=0)]\n",
    "        clf.fit(df_trainX,\n",
    "                df_trainY,#)\n",
    "                eval_set=[(df_evalX, df_evalY)],\n",
    "                callbacks=callbacks,\n",
    "                # verbose=0\n",
    "               )\n",
    "\n",
    "        valid_score = roc_auc_score(df_evalY!='NoActivity', 1-clf.predict_proba(df_evalX)[:,1])\n",
    "        best_iteration = clf.booster_.best_iteration\n",
    "        feature_score = clf.feature_importances_\n",
    "    return clf, valid_score, best_iteration, feature_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\acer\\Documents\\MyDocs\\Programming\\VisualCode\\ds_project_intro\\modeling.ipynb Cell 56\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/acer/Documents/MyDocs/Programming/VisualCode/ds_project_intro/modeling.ipynb#Y106sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTrain_fe.csv.gz\u001b[39m\u001b[39m\"\u001b[39m, compression\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/acer/Documents/MyDocs/Programming/VisualCode/ds_project_intro/modeling.ipynb#Y106sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39m./Test_fe.csv.gz\u001b[39m\u001b[39m\"\u001b[39m, compression\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39mto_csv(\n\u001b[0;32m   3721\u001b[0m     path_or_buf,\n\u001b[0;32m   3722\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[0;32m   3723\u001b[0m     sep\u001b[39m=\u001b[39msep,\n\u001b[0;32m   3724\u001b[0m     encoding\u001b[39m=\u001b[39mencoding,\n\u001b[0;32m   3725\u001b[0m     errors\u001b[39m=\u001b[39merrors,\n\u001b[0;32m   3726\u001b[0m     compression\u001b[39m=\u001b[39mcompression,\n\u001b[0;32m   3727\u001b[0m     quoting\u001b[39m=\u001b[39mquoting,\n\u001b[0;32m   3728\u001b[0m     columns\u001b[39m=\u001b[39mcolumns,\n\u001b[0;32m   3729\u001b[0m     index_label\u001b[39m=\u001b[39mindex_label,\n\u001b[0;32m   3730\u001b[0m     mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m   3731\u001b[0m     chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[0;32m   3732\u001b[0m     quotechar\u001b[39m=\u001b[39mquotechar,\n\u001b[0;32m   3733\u001b[0m     date_format\u001b[39m=\u001b[39mdate_format,\n\u001b[0;32m   3734\u001b[0m     doublequote\u001b[39m=\u001b[39mdoublequote,\n\u001b[0;32m   3735\u001b[0m     escapechar\u001b[39m=\u001b[39mescapechar,\n\u001b[0;32m   3736\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m   3737\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:261\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[1;32m--> 261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:266\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_need_to_save_header:\n\u001b[0;32m    265\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_header()\n\u001b[1;32m--> 266\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_body()\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:304\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mif\u001b[39;00m start_i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m end_i:\n\u001b[0;32m    303\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_chunk(start_i, end_i)\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:315\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    312\u001b[0m data \u001b[39m=\u001b[39m [res\u001b[39m.\u001b[39miget_values(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(res\u001b[39m.\u001b[39mitems))]\n\u001b[0;32m    314\u001b[0m ix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_index[slicer]\u001b[39m.\u001b[39m_format_native_types(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_number_format)\n\u001b[1;32m--> 315\u001b[0m libwriters\u001b[39m.\u001b[39mwrite_csv_rows(\n\u001b[0;32m    316\u001b[0m     data,\n\u001b[0;32m    317\u001b[0m     ix,\n\u001b[0;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnlevels,\n\u001b[0;32m    319\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcols,\n\u001b[0;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter,\n\u001b[0;32m    321\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\writers.pyx:55\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\Lib\\gzip.py:289\u001b[0m, in \u001b[0;36mGzipFile.write\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    286\u001b[0m     length \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mnbytes\n\u001b[0;32m    288\u001b[0m \u001b[39mif\u001b[39;00m length \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfileobj\u001b[39m.\u001b[39mwrite(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompress\u001b[39m.\u001b[39mcompress(data))\n\u001b[0;32m    290\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m length\n\u001b[0;32m    291\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrc \u001b[39m=\u001b[39m zlib\u001b[39m.\u001b[39mcrc32(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrc)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train.to_csv(\"./Train_fe.csv.gz\", compression='gzip')\n",
    "# test.to_csv(\"./Test_fe.csv.gz\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Fold 1 0.9036743334688541 at 641\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Fold 2 0.9051100380755172 at 859\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Fold 3 0.9071185050771372 at 529\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Fold 4 0.9030715240527301 at 907\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Fold 5 0.9079838809657259 at 1106\n",
      "The local CV is 0.9053956575037196\n",
      "CPU times: total: 1h 30min 30s\n",
      "Wall time: 23min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "drop_cols = [\n",
    "    'year', 'month', 'Target', 'Sub', 'CompPart', 'Comment', 'Disc',\n",
    "    'is_train', 'timestamp', 'Record', 'Active_Month', 'Total_Num_User_Months',\n",
    "    'user_interests'\n",
    "]\n",
    "cat_cols = list(\n",
    "    set(train.columns[train.dtypes == 'object']) - set(drop_cols) - set(['User_ID'])\n",
    ")\n",
    "num_cols = list(set(train.columns) - set(cat_cols + drop_cols))\n",
    "\n",
    "train_X = train[cat_cols + num_cols]\n",
    "train_X[cat_cols] = train_X[cat_cols].astype('category')\n",
    "train_Y = train['Target']\n",
    "\n",
    "test_X = test[cat_cols + num_cols]\n",
    "test_X[cat_cols] = test_X[cat_cols].astype('category')\n",
    "\n",
    "fold = GroupKFold(n_splits=5)\n",
    "cb_scores, pred_cb, feat_scores = [], [], []\n",
    "for it, (idxT, idxV) in enumerate(\n",
    "        fold.split(train_X, train_Y, groups=train['timestamp'])):\n",
    "    df_trainX, df_trainY = train_X.iloc[idxT], train_Y.iloc[idxT]\n",
    "    df_evalX, df_evalY = train_X.iloc[idxV], train_Y.iloc[idxV]\n",
    "    df_testX = test_X.copy()\n",
    "\n",
    "    selected_cat_cols = ['Country']\n",
    "    cat_cols_count = [f'{col}_count' for col in selected_cat_cols]\n",
    "    df_trainX[cat_cols_count] = df_trainX[selected_cat_cols].copy()\n",
    "    df_evalX[cat_cols_count] = df_evalX[selected_cat_cols].copy()\n",
    "    df_testX[cat_cols_count] = df_testX[selected_cat_cols].copy()\n",
    "\n",
    "    encoder = CountEncoder(cols=cat_cols_count + ['User_ID'])\n",
    "    df_trainX = encoder.fit_transform(df_trainX, df_trainY)\n",
    "    df_evalX = encoder.transform(df_evalX)\n",
    "    df_testX = encoder.transform(df_testX)\n",
    "\n",
    "    clf, valid_score, best_iteration, feature_score = train_model(\n",
    "        df_trainX, df_trainY, df_evalX, df_evalY, cat_cols, model_name='LGB')\n",
    "    cb_scores.append(valid_score)\n",
    "    pred_cb.append(clf.predict_proba(df_testX)[:, 1])\n",
    "    feat_scores.append(feature_score)\n",
    "    print('Fold {} {} at {}'.format(it + 1, valid_score, best_iteration))\n",
    "\n",
    "weights = cb_scores / sum(np.array(cb_scores))\n",
    "print('The local CV is {}'.format(np.sum(weights * cb_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if LOCAL_TEST_RUN:\n",
    "#     weights=cb_scores/sum(np.array(cb_scores))\n",
    "#     print ('The local CV is {}'.format(np.sum(weights*cb_scores)))\n",
    "\n",
    "#     prediction = np.sum(weights*np.transpose(pred_cb),1)\n",
    "#     from sklearn.metrics import roc_auc_score\n",
    "#     print(\"Test score is {}\".format(roc_auc_score(test['Target']!='NoActivity', 1-prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Num_Comp_Per_Month_trend</td>\n",
       "      <td>9.332327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Num_Sub_Prev_Month</td>\n",
       "      <td>9.162825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Num_Comp_Prev_Month</td>\n",
       "      <td>7.332450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Num_Comp_Per_Month</td>\n",
       "      <td>6.218203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Points</td>\n",
       "      <td>4.580333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Current_Active_Competitions</td>\n",
       "      <td>3.692354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Months_Since_Last_Sub</td>\n",
       "      <td>3.206898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>comp_timestamp</td>\n",
       "      <td>3.084732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zindi_Joining_Timestamp</td>\n",
       "      <td>3.069153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Num_Comm_Per_Month_trend</td>\n",
       "      <td>2.953063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Country</td>\n",
       "      <td>2.531538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>user_interests_rank</td>\n",
       "      <td>2.500494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Num_Comm_Prev_Month</td>\n",
       "      <td>2.348918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Total_Num_User_Months_max</td>\n",
       "      <td>1.978381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Months_Since_Last_Comp</td>\n",
       "      <td>1.902657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Num_Sub_Prev_Month_momentum</td>\n",
       "      <td>1.848240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Months_Since_Joining_Zindi</td>\n",
       "      <td>1.690571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sub_timestamp</td>\n",
       "      <td>1.687076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>User_ID</td>\n",
       "      <td>1.524167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Country_count</td>\n",
       "      <td>1.518305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Total_Num_User_Months_mean</td>\n",
       "      <td>1.478673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Num_Comp_Prev_Month_momentum</td>\n",
       "      <td>1.413789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Num_Comm_Per_Month</td>\n",
       "      <td>1.302475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Months_Since_Sub_Joining_Zindi</td>\n",
       "      <td>1.286928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Num_Sub_Per_Month_trend</td>\n",
       "      <td>1.281860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>unique_user_count</td>\n",
       "      <td>1.270853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>year_month</td>\n",
       "      <td>1.196361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Num_Sub_Prev_Month_momentum2</td>\n",
       "      <td>1.179623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Num_Dis_Prev_Month</td>\n",
       "      <td>1.115478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Num_Sub_Per_Month</td>\n",
       "      <td>1.068755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FeatureG_1</td>\n",
       "      <td>1.066054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Num_Comp_Prev_Month_momentum2</td>\n",
       "      <td>0.810063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Successful_Sub_Count_count 10</td>\n",
       "      <td>0.777314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Months_Since_Last_Activity_Mean</td>\n",
       "      <td>0.713498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>FeatureX</td>\n",
       "      <td>0.678246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Total_Num_User_Months_std</td>\n",
       "      <td>0.676605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>comment_timestamp</td>\n",
       "      <td>0.593626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Num_Dis_Per_Month_trend</td>\n",
       "      <td>0.526479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Successful_Sub_Count_count 6</td>\n",
       "      <td>0.521325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>PublicRank_rank 11</td>\n",
       "      <td>0.500306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Successful_Sub_Count_count 3</td>\n",
       "      <td>0.496669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>User_ID_nunique</td>\n",
       "      <td>0.492443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Months_Since_Last_Dis</td>\n",
       "      <td>0.471345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Successful_Sub_Count_count 7</td>\n",
       "      <td>0.439857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>FeatureG_0</td>\n",
       "      <td>0.419489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Num_Comm_Prev_Month_momentum</td>\n",
       "      <td>0.418137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>FeatureY</td>\n",
       "      <td>0.405569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Months_Since_Last_Comment</td>\n",
       "      <td>0.392811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Successful_Sub_Count_count 5</td>\n",
       "      <td>0.358721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Successful_Sub_Count_count 8</td>\n",
       "      <td>0.349723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Num_Dis_Per_Month</td>\n",
       "      <td>0.339067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>discussion_timestamp</td>\n",
       "      <td>0.317568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>FeatureG_3</td>\n",
       "      <td>0.307045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Successful_Sub_Count_count 9</td>\n",
       "      <td>0.294030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>PublicRank_rank 1</td>\n",
       "      <td>0.284458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Months_Since_Comment_Joining_Zindi</td>\n",
       "      <td>0.274468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Num_Dis_Prev_Month_momentum</td>\n",
       "      <td>0.260070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Months_Since_Dis_Joining_Zindi</td>\n",
       "      <td>0.259348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Num_Comm_Prev_Month_momentum2</td>\n",
       "      <td>0.251303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>PublicRank_rank 10</td>\n",
       "      <td>0.237760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Num_Dis_Prev_Month_momentum2</td>\n",
       "      <td>0.218190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>PublicRank_rank 2</td>\n",
       "      <td>0.168567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>PublicRank_rank 9</td>\n",
       "      <td>0.162203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>PublicRank_rank 5</td>\n",
       "      <td>0.154776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Successful_Sub_Count_count 4</td>\n",
       "      <td>0.145531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>PublicRank_rank 8</td>\n",
       "      <td>0.104218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>PublicRank_rank 6</td>\n",
       "      <td>0.100442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>PublicRank_rank 7</td>\n",
       "      <td>0.100117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>PublicRank_rank 3</td>\n",
       "      <td>0.099149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>PublicRank_rank 4</td>\n",
       "      <td>0.055928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature  importance\n",
       "0             Num_Comp_Per_Month_trend    9.332327\n",
       "1                   Num_Sub_Prev_Month    9.162825\n",
       "2                  Num_Comp_Prev_Month    7.332450\n",
       "3                   Num_Comp_Per_Month    6.218203\n",
       "4                               Points    4.580333\n",
       "5          Current_Active_Competitions    3.692354\n",
       "6                Months_Since_Last_Sub    3.206898\n",
       "7                       comp_timestamp    3.084732\n",
       "8              Zindi_Joining_Timestamp    3.069153\n",
       "9             Num_Comm_Per_Month_trend    2.953063\n",
       "10                             Country    2.531538\n",
       "11                 user_interests_rank    2.500494\n",
       "12                 Num_Comm_Prev_Month    2.348918\n",
       "13           Total_Num_User_Months_max    1.978381\n",
       "14              Months_Since_Last_Comp    1.902657\n",
       "15         Num_Sub_Prev_Month_momentum    1.848240\n",
       "16          Months_Since_Joining_Zindi    1.690571\n",
       "17                       sub_timestamp    1.687076\n",
       "18                             User_ID    1.524167\n",
       "19                       Country_count    1.518305\n",
       "20          Total_Num_User_Months_mean    1.478673\n",
       "21        Num_Comp_Prev_Month_momentum    1.413789\n",
       "22                  Num_Comm_Per_Month    1.302475\n",
       "23      Months_Since_Sub_Joining_Zindi    1.286928\n",
       "24             Num_Sub_Per_Month_trend    1.281860\n",
       "25                   unique_user_count    1.270853\n",
       "26                          year_month    1.196361\n",
       "27        Num_Sub_Prev_Month_momentum2    1.179623\n",
       "28                  Num_Dis_Prev_Month    1.115478\n",
       "29                   Num_Sub_Per_Month    1.068755\n",
       "30                          FeatureG_1    1.066054\n",
       "31       Num_Comp_Prev_Month_momentum2    0.810063\n",
       "32       Successful_Sub_Count_count 10    0.777314\n",
       "33     Months_Since_Last_Activity_Mean    0.713498\n",
       "34                            FeatureX    0.678246\n",
       "35           Total_Num_User_Months_std    0.676605\n",
       "36                   comment_timestamp    0.593626\n",
       "37             Num_Dis_Per_Month_trend    0.526479\n",
       "38        Successful_Sub_Count_count 6    0.521325\n",
       "39                  PublicRank_rank 11    0.500306\n",
       "40        Successful_Sub_Count_count 3    0.496669\n",
       "41                     User_ID_nunique    0.492443\n",
       "42               Months_Since_Last_Dis    0.471345\n",
       "43        Successful_Sub_Count_count 7    0.439857\n",
       "44                          FeatureG_0    0.419489\n",
       "45        Num_Comm_Prev_Month_momentum    0.418137\n",
       "46                            FeatureY    0.405569\n",
       "47           Months_Since_Last_Comment    0.392811\n",
       "48        Successful_Sub_Count_count 5    0.358721\n",
       "49        Successful_Sub_Count_count 8    0.349723\n",
       "50                   Num_Dis_Per_Month    0.339067\n",
       "51                discussion_timestamp    0.317568\n",
       "52                          FeatureG_3    0.307045\n",
       "53        Successful_Sub_Count_count 9    0.294030\n",
       "54                   PublicRank_rank 1    0.284458\n",
       "55  Months_Since_Comment_Joining_Zindi    0.274468\n",
       "56         Num_Dis_Prev_Month_momentum    0.260070\n",
       "57      Months_Since_Dis_Joining_Zindi    0.259348\n",
       "58       Num_Comm_Prev_Month_momentum2    0.251303\n",
       "59                  PublicRank_rank 10    0.237760\n",
       "60        Num_Dis_Prev_Month_momentum2    0.218190\n",
       "61                   PublicRank_rank 2    0.168567\n",
       "62                   PublicRank_rank 9    0.162203\n",
       "63                   PublicRank_rank 5    0.154776\n",
       "64        Successful_Sub_Count_count 4    0.145531\n",
       "65                   PublicRank_rank 8    0.104218\n",
       "66                   PublicRank_rank 6    0.100442\n",
       "67                   PublicRank_rank 7    0.100117\n",
       "68                   PublicRank_rank 3    0.099149\n",
       "69                   PublicRank_rank 4    0.055928"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureImp=pd.DataFrame({'feature':df_trainX.columns,'importance':np.mean(np.array(feat_scores),0)})\n",
    "featureImp=featureImp.sort_values('importance',ascending=False)\n",
    "featureImp['importance']=featureImp['importance']*100/featureImp['importance'].sum()\n",
    "featureImp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Target'] = np.sum(weights * np.transpose(pred_cb), 1)\n",
    "test['Target'] = 1 - test['Target']\n",
    "test['UserMonthYear'] = test['User_ID'] + \"_\" + test['month'].astype(str) + \"_\" + test['year'].astype(str)\n",
    "test[['UserMonthYear', 'Target']].to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserMonthYear</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ID_000VV0KM_1_4</td>\n",
       "      <td>0.015220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ID_000VV0KM_2_4</td>\n",
       "      <td>0.015055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ID_000VV0KM_3_4</td>\n",
       "      <td>0.010345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ID_003OCIYO_1_4</td>\n",
       "      <td>0.326021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ID_003OCIYO_2_4</td>\n",
       "      <td>0.017102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325041</th>\n",
       "      <td>ID_ZZVPF22K_2_4</td>\n",
       "      <td>0.168025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325042</th>\n",
       "      <td>ID_ZZVPF22K_3_4</td>\n",
       "      <td>0.120570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325052</th>\n",
       "      <td>ID_ZZXDLYXB_1_4</td>\n",
       "      <td>0.008189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325053</th>\n",
       "      <td>ID_ZZXDLYXB_2_4</td>\n",
       "      <td>0.008052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325054</th>\n",
       "      <td>ID_ZZXDLYXB_3_4</td>\n",
       "      <td>0.007621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65223 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          UserMonthYear    Target\n",
       "13      ID_000VV0KM_1_4  0.015220\n",
       "14      ID_000VV0KM_2_4  0.015055\n",
       "15      ID_000VV0KM_3_4  0.010345\n",
       "16      ID_003OCIYO_1_4  0.326021\n",
       "17      ID_003OCIYO_2_4  0.017102\n",
       "...                 ...       ...\n",
       "325041  ID_ZZVPF22K_2_4  0.168025\n",
       "325042  ID_ZZVPF22K_3_4  0.120570\n",
       "325052  ID_ZZXDLYXB_1_4  0.008189\n",
       "325053  ID_ZZXDLYXB_2_4  0.008052\n",
       "325054  ID_ZZXDLYXB_3_4  0.007621\n",
       "\n",
       "[65223 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[['UserMonthYear', 'Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
